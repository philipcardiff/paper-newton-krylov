
 
\documentclass[sn-mathphys,Numbered]{sn-jnl}% Math and Physical Sciences Reference Style
%\documentclass[sn-mathphys,Numbered,draft]{sn-jnl}% Math and Physical Sciences Reference Style

%%\documentclass[sn-nature]{sn-jnl}% Style for submissions to Nature Portfolio journals
%%\documentclass[sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style
%%\documentclass[sn-aps]{sn-jnl}% American Physical Society (APS) Reference Style
%%\documentclass[sn-vancouver,Numbered]{sn-jnl}% Vancouver Reference Style
%%\documentclass[sn-apa]{sn-jnl}% APA Reference Style 
%%\documentclass[sn-chicago]{sn-jnl}% Chicago-based Humanities Reference Style
%%\documentclass[default]{sn-jnl}% Default
%%\documentclass[default,iicol]{sn-jnl}% Default with double column layout

%%%% Standard Packages
%%<additional latex packages, if required can be included here>

\setlength{\parskip}{\baselineskip}

\usepackage{graphicx}%
\usepackage{amsmath,amssymb,amsfonts,bm}%
\usepackage{multirow}
\usepackage{amsthm}%
%\usepackage{subcaption}
\usepackage{mathrsfs}%
\usepackage[title]{appendix}%
\usepackage{xcolor}%
\usepackage{textcomp}%
\usepackage{manyfoot}%
\usepackage{booktabs}%
%\usepackage{algorithm}%
%\usepackage{algorithmicx}%
\usepackage{algpseudocode}%
\usepackage{listings}%
\usepackage{bigints}
\usepackage{outlines}
\usepackage{geometry}
\usepackage{subfigure}
\usepackage{siunitx}
\usepackage{float}

\geometry
{
a4paper,         % or letterpaper
textwidth=15cm,  % llncs has 12.2cm
textheight=24cm, % llncs has 19.3cm
% heightrounded,   % integer number of lines
% hratio=1:1,      % horizontally centered
% vratio=2:3,      % not vertically centered
}
\setlength{\tabcolsep}{0.5cm}
\usepackage[onehalfspacing]{setspace}
% \usepackage{lineno}
% \linenumbers
%%%%

\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage[ruled,vlined]{algorithm2e}
\usepackage{amsmath}
%\usepackage{movie15} %to allow movie embedding
\usepackage[section]{placeins}
\usepackage{enumitem}
\usepackage{color,soul}
\usepackage{xfrac}

%% New math commands
\newcommand{\s}[1]{\overset{*}{#1}}
\newcommand{\RM}{\bm{\Lambda}}
\newcommand{\RMI}{\bm{\Lambda}_0}
\newcommand{\RMT}{\bm{\Lambda}_t}
\newcommand{\RV}{\bm{\psi}}
\newcommand{\magRV}{\psi}
\newcommand{\RMTS}{\s{\bm{\Lambda}}_t}
\newcommand{\bb}{\boldsymbol}

%% For contact
\newcommand{\rbar}{\bar{\bm{r}}}
\newcommand{\xibar}{\bar{\xi}}
%\newcommand{\magRV}{\bbit{\psi}}
\newcommand{\diag}{\rm diag}

\begin{document}

\title[Article Title]{Assessing the potential of Jacobian-free Newton-Krylov methods for cell-centred finite volume solid mechanics}

\author*[1,2,3]{\fnm{Philip} \sur{Cardiff}}\email{philip.cardiff@ucd.ie}
\author[4]{\fnm{Ivan} \sur{Batisti\'{c}}}
\author[4]{\fnm{\v{Z}eljko} \sur{Tukovi\'{c}}}

\affil*[1]{\orgdiv{School of Mechanical and Materials Engineering}, \orgname{University College Dublin}, \orgaddress{\country{Ireland}}}
\affil[2]{\orgdiv{UCD Centre for Mechanics}, \orgname{University College Dublin}, \orgaddress{\country{Ireland}}}
\affil[3]{\orgdiv{SFI I-Form Centre}, \orgname{University College Dublin}, \orgaddress{\country{Ireland}}}
\affil[4]{\orgdiv{Faculty of Mechanical Engineering and Naval Architecture}, \orgname{University of Zagreb}, \orgaddress{\country{Croatia}}}



\abstract
{
In this study, we explore the efficacy of Jacobian-free Newton-Krylov methods within the context of finite-volume solid mechanics.
Traditional Newton-based approaches to solving nonlinear systems typically require explicit formation and storage of the Jacobian matrix, which can be computationally expensive and memory-intensive.
The Jacobian-free Newton-Krylov method circumvents this by employing Krylov subspace iterative solvers, such as GMRES, in conjunction with a Newton iteration scheme that approximates the action of the Jacobian through finite difference evaluations.
A further potential advantage of the Jacobian-free Newton-Krylov method is that it is readily applicable to existing segregated finite volume frameworks, where forming and storing the exact Jacobian would require major code refactoring.
%This approach promises significant computational savings, especially for large-scale, complex simulations prevalent in solid mechanics.
This article research systematically evaluates the performance of Jacobian-free Newton-Krylov methods by benchmarking them against conventional segregated methods on a suite of benchmark cases of varying geometric dimension, geometric nonlinearity, dynamic response, and material behaviour.
Key metrics such as computational cost, memory and robustness are analysed.
Additionally, we investigate the impact of various solution algorithm choices, such as preconditioning strategy, on the efficiency of the Jacobian-free Newton-Krylov method.
Our findings indicate that Jacobian-free Newton-Krylov methods can achieve \hl{comparable/superior/XXX convergence behaviour} relative to traditional segregated methods, particularly in cases where YYYY.
\hl{Summarise key findings: time, memory, important choices, JFNK vs SEG vs FE, ...}
The results suggest that Jacobian-free Newton-Krylov methods are promising for advancing finite-volume solid mechanics simulations and are particularly attractive for existing segregated frameworks where minimal code changes would be required to exploit openly available Jacobian-free Newton-Krylov implementations.
The described implementations are made publicly available in the solids4foam toolbox for OpenFOAM, allowing the community to examine, extend and compare the procedures with the our codes.
%offering a viable pathway for enhancing computational efficiency and scalability.
%EMPHASISE: easy to extend segregated frameworks, on contrast to exact Jacobian methoods.
%This study provides critical insights and practical guidelines for implementing JFNK methods in engineering and scientific applications.
%Key FV points:
%- many FV codes were developed around a segregated solution procedure, which requires significant effort to extend to a full Newton method, e.g. in terms of Jacobian assembly, storage, and linear system solution.
%- this paper examines Jacobian-free Newton-Krylov as a straight-forward extension of the segregated approach, without the need for a full Jacobian based method.
%- compact approximate Jacobian for preconditioner (more compact than FE approach)
%- implemented in OpenFOAM, and code and cases are made publicly available.
}



\keywords{Jacobian-free Newton-Krylov, Finite volume method, GMRES, OpenFOAM}

\maketitle


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}\label{sec:intro}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%Paper outline:
%
%Intro
%- FV is of interest for CSM
%- Most methods use segregated algorithms, stemming from CFD algorithms
%- Extension to block-coupled Newton methods is not easy, in terms of derivation, and code refactoring (matrix storage, extended stencil, linear solver, etc.).
%- JFNK promises the performance of Newton methods, but without the need to form the full Jacobian. Define JFNK method. Hence, an existing segregated code can easily be adapted to use JFNK without major refactoring, albeit this process is made easier by the availability of open-source JFNK implementations.
%- this paper examines JFNK for linear and nonlinear FV CSM procedures, where the compact stencil approximate Jacobian is used for preconditioning.



Finite volume formulations for solid mechanics are heavily influenced by their fluid mechanics counterparts, favouring segregated implicit and fully explicit methods.
Segregated approaches, where the governing momentum equation is temporarily decomposed into scalar component equations, offer memory efficiency and simplicity of implementation, but the outer coupling Picard iterations often suffer from slow convergence.
Explicit formulations are straightforward to implement and offer superior robustness but are only efficient for high-speed dynamics, where the physics requires small time increments.
In contrast, the finite element community commonly employs Newton-Raphson-type solution algorithms, which necessitate repeated assembly of the Jacobian matrix and solution of the resulting block-coupled non-diagonally dominant linear system.
A disadvantage of traditional Newton-based approaches is that they typically require explicit formation and storage of the Jacobian matrix, which can be computationally expensive and memory-intensive.
A further disadvantage from a finite volume perspective is that extending existing code frameworks from segregated algorithms to a coupled Newton-Raphson-type approach is challenging in terms of the required assembly, storage, and solution of the resulting block-coupled system.
In addition, the derivation of the true Jacobian matrix is non-trivial.
Consequently, similar block-coupled solution finite volume methods are rare in the literature \citep{Das2011, Cardiff2016, Castrillo2024}.
The motivation of the current work is to seek (or exceed) the robustness and efficiency of block-coupled Newton-Raphons approaches in a way that can be easily incorporated into existing segregated solution frameworks.
To this end, the current article examines the efficacy of \emph{Jacobian-free} Newton-Krylov methods, where the quadratic convergence of Newton methods can potentially be achieved without deriving, assembling and storing the exact Jacobian.

Jacobian-free Newton-Krylov methods circumvent the need for the Jacobian matrix by combining the Newton-Raphson method with Krylov subspace iterative linear solvers, such as GMRES, and noticing that such Krylov solvers do not explicitly require the Jacobian matrix.
Instead, only the action of the Jacobian matrix on a solution-type vector is required.
The key step in Jacobian-free Newton-Krylov methods is the approximation of products between the Jacobian matrix and a vector using the finite difference method; that is
\begin{eqnarray}
	\bb{J} \bb{v} \approx \frac{\bb{F}(\bb{x} + \epsilon \bb{v}) - \bb{F}(\bb{x})}{\epsilon}
\end{eqnarray}
where $\mathbf{J}$ is the Jacobian matrix, $\mathbf{x}$ is the current solution vector (e.g. nodal displacements), $\mathbf{v}$ is a vector (e.g., from a Krylov subspace), and $\epsilon$ is a small scalar perturbation.
%Determining the appropriate value for $\epsilon$ requires balancing the truncation error of the finite difference approximation and round-off (numerical precision) error.
With an appropriate choice of $\epsilon$ (balancing truncation and round-off errors), the characteristic quadratic convergence of Newton methods can be achieved without the Jacobian, hence the modifier \emph{Jacobian-free}.
This approach promises significant memory savings over Jacobian-based methods, especially for large-scale, but also potentially for execution time, with appropriate choice of solution components.

A crucial aspect of ensuring the efficiency and robustness of the Jacobian-free Newton-Krylov method is the choice of a suitable preconditioner for the Krylov iterations.
This preconditioner is often derived from the exact Jacobian matrix in traditional Newton methods.
However, the Jacobian-free approach does not allow direct access to the full Jacobian matrix, necessitating an alternative strategy to approximate its action.
To this end, and to extend existing segregated frameworks, we propose using a compact-stencil approximate Jacobian as the preconditioner. This approximate Jacobian corresponds to the matrix typically employed in segregated approaches; similar approaches are successful in fluid mechanics applications \citep{Nishikawa2020, nonNewtonianJFNKPaper}; however, it is unclear if such an approach is suitable for solid mechanics - a question which we hope to answer in this work.
By leveraging this compact-stencil approximate Jacobian, we aim to effectively precondition the Krylov iterations, enhancing convergence while maintaining the memory and computational savings that define the Jacobian-free and segregated methods.
Similarly, if such an approach is efficient, it would naturally fit into existing segregated frameworks, as existing matrix storage and assembly can be reused.

The remainder of the paper is structured as follows:
Section 2 summarises a typical solid mechanics mathematical model and its cell-centred finite volume discretisation.
Section 3 presents the solution algorithms, starting with the classic segregated solution algorithm, followed by the proposed Jacobian-free Newton-Krylov solution algorithm.
The performance of the proposed Jacobian-free Newton-Krylov approach is compared with the segregated approach on several varying benchmark cases in Section 4, where the effect of several factors are examined, including problem dimension, mesh, material model, nonlinear geometry, choice of preconditioner, and other solution parameter.
Finally, the article ends with a summary of the main conclusions of the work.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Mathematical Model and Numerical Methods}\label{sec:math_model}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%
%Math model and numerical methods
%- General governing equation -> unknown D; limit ourselves to compressibility

\subsection{Governing Equations} \label{sec:governing_eqn}

In this work, we restrict our interest to Lagrangian formulations of the conservation of linear momentum.
Assuming small strains, the linear geometry formulation is expressed in strong integral form as:
\begin{eqnarray} \label{eqn:momentum_lingeom}
    \int_{\Omega} \rho \frac{\partial^2 \bb{u} }{\partial t^2} \, d\Omega
    =
    \oint_{\Gamma} \bb{n} \cdot \bb{\sigma}_s \,  d\Gamma
    + \int_{\Omega}  \bb{f}_b \, d\Omega
\end{eqnarray}
where $\Omega$ is the volume of an arbitrary body bounded by a surface $\Gamma$ with outwards pointing normal $\bb{n}$.
The density is $\rho$, $\bb{u}$ is the displacement vector, $\bb{\sigma}_s$ is the engineering (small strain) stress tensor, and $\bb{f}_b$ is a body force per unit volume, e.g., $\rho \bb{g}$, where $\bb{g}$ is gravity.

More generally,  linear momentum conservation can be expressed in a nonlinear geometry form, which is suitable for finite strains.
Two equivalent nonlinear geometry forms are common: the \emph{total} Lagrangian form:
\begin{eqnarray} \label{eqn:momentum_TL}
    \int_{\Omega_o} \rho_o \frac{\partial^2 \bb{u} }{\partial t^2} d\Omega_o
    =
    \oint_{\Gamma_o} \left( J \bb{F}^{-T} \cdot \bb{n}_o \right) \cdot \bb{\sigma} \ d\Gamma_o
    + \int_{\Omega_o}  \rho_o \bb{g} \, d\Omega_o
\end{eqnarray}
and the \emph{updated} Lagrangian form:
\begin{eqnarray} \label{eqn:momentum_UL}
    \int_{\Omega_u} \frac{\partial }{\partial t} \left( \rho_u \frac{\partial \bb{u} }{\partial t} \right) d\Omega_u
    = \oint_{\Gamma_u}(j\bb{f}^{-T}\cdot{\bb{n}_u)\cdot \bb{\sigma}}\ d\Gamma_u
    + \int_{\Omega_u}  \rho_u \bb{g} \, d\Omega_u
\end{eqnarray}
where subscript $o$ indicates quantities in the initial reference configuration, and subscript $u$ indicates quantities in the updated configuration.
The true (Cauchy) stress tensor is indicated by $\bb{\sigma}$.

The deformation gradient is defined as $\bb{F} = \textbf{I} + (\bb{\nabla} \bb{u})^T$ and its determinant as $J = \text{det}(\bb{F})$.
Similarly, the \emph{relative} deformation gradient is given in terms of the displacement \emph{increment} as $\bb{f}=\textbf{I} + \left[\bb{\nabla}(\Delta \bb{u}) \right]^T$ and its determinant as $j = \text{det}(\bb{f})$.
The displacement increment is the change in displacement between the current time step and the previous time step when the time interval is discretised into a finite number of steps.

%The two forms are connected through Nanson’s formula \cite{bathe_finite_1996}, which relate the deformed area vector $\bb{\Gamma}$ with the initial area vector $\bb{\Gamma}_{o}$:
%\begin{equation}
%    \bb{\Gamma} = J\bb{F}^{-T}\cdot\bb{\Gamma}_o
%\end{equation}


%Although the total Lagrangian approach is a viable option for wire drawing, the current work adopts the updated Lagrangian approach as developing Eulerian-type upstream and downstream conditions (Section \ref{sec:euler_BCs}) is conceptually easier in an updated Lagrangian formulation.

The definition of the engineering stress ($\bb{\sigma}_s$) and true stress ($\bb{\sigma}$) in Equations \ref{eqn:momentum_lingeom}, \ref{eqn:momentum_TL} and \ref{eqn:momentum_UL} is given by a chosen mechanical law, e.g. linear elasticity.
Several mechanical laws are considered in this work, as briefly described in Section \ref{sec:test_cases}.



%%--------------------------------------------------------------------------------------------------------------------%%
\subsection{Newton-Type Solution Methods}
%%--------------------------------------------------------------------------------------------------------------------%%
To facilitate the comparison between classic segregated solution algorithms and the proposed Jacobian-free Newton-Krylov algorithm, the governing linear momentum conservation (Equations \ref{eqn:momentum_lingeom}, \ref{eqn:momentum_TL} and \ref{eqn:momentum_UL}) is expressed in the general form:
\begin{eqnarray} \label{eqn:residual}
	\mathcal{R}(\bb{u}) = \bb{0}
\end{eqnarray}
where $\mathcal{R}$ represents the \emph{residual} (imbalance) of the equation, which is a function of the primary unknown field.
For example, in the linear geometry case, the residual is given as
\begin{eqnarray}
    \bb{R}(\bb{u})
    \;=\;
    \oint_{\Gamma} \bb{n} \cdot \bb{\sigma}_s(\bb{u}) \,  d\Gamma
    + \int_{\Omega}  \rho \bb{g} \, d\Omega
    -  \int_{\Omega} \rho \frac{\partial^2 \bb{u} }{\partial t^2} \, d\Omega
    \;=\; \bb{0}
\end{eqnarray}
where the dependence of the stress tensor on the solution vector is made explicitly clear: $\bb{\sigma}_s(\bb{u})$.



In Newton-type methods, a Taylor expansion about a current point $\bb{u}_k$ can be used to solve Equation \ref{eqn:residual} \cite{Knoll2004}:
\begin{eqnarray}
	\bb{R}(\bb{u}_{k+1}) = \bb{R}(\bb{u}_{k}) \;+\;  \bb{R}'(\bb{u}_{k}) (\bb{u}_{k+1} - \bb{u}_{k}) \;+\; \text{H.O.T.} = \bb{0}
\end{eqnarray}
Neglecting the higher-order terms ($\text{H.O.T.}$) yields the strict Newton method in terms of an iteration over a sequence of linear systems: 
\begin{eqnarray} \label{eq:NewtonRaphson}
	\bb{J}(\bb{u}_k) \delta \bb{u} &=& -\bb{R}(\bb{u}_n), \notag \\
	\bb{u}_{k+1} &=& \bb{u}_k + s \, \delta \bb{u}, \notag \\
	\quad
	k &=& 0,1,...
%    \label{eq:NewtonRaphsonA}
%    \overbrace{\left[ \frac{\partial \mathcal{R}(\bb{u})}{\partial \bb{u}} \right]_n}^{\mathcal{J}} \Delta \bb{u} = -\mathcal{R}(\bb{u})_n \\
%    \label{eq:NewtonRaphsonB}
%    \bb{u}_{n+1} = \bb{u}_{n} + \alpha \Delta \bb{u}
\end{eqnarray}
where $\bb{J} \equiv \bb{R}'$ is the Jacobian matrix.
Starting the Newton procedure requires the specification of $\bb{u}_0$.
%is iteratively solved by linearisation about the current value of the solution, leading to a linear system and iterative update of the solution vector:
%\begin{eqnarray}
%    \label{eq:NewtonRaphsonA}
%    \overbrace{\left[ \frac{\partial \mathcal{R}(\bb{u})}{\partial \bb{u}} \right]_n}^{\mathcal{J}} \Delta \bb{u} = -\mathcal{R}(\bb{u})_n \\
%    \label{eq:NewtonRaphsonB}
%    \bb{u}_{n+1} = \bb{u}_{n} + \alpha \Delta \bb{u}
%\end{eqnarray}
%where subscript $n$ indicates the outer (Newton) iteration index.
The scalar $s > 0$ can be chosen to improve convergence, for example, using a line search or under-relaxation procedure, and is equal to unity in the classic Newton-Raphson approach.
Iterations are performed over this system until the residual $\bb{R}(\bb{u}_n)$ and solution correction $\delta \bb{u}$ are sufficiently small, with appropriate normalisation.

%\hl{$\Delta u$: we are using in two ways: increment and correction. Fix this!}
%\hl{KnollKeyes give a nice concise description of Newton: check}

For problems with $N$ scalar equations and $N$ scalar unknowns, the residual $\bb{R}$ and solution $\bb{u}$ vectors have dimensions of $N \times 1$. %, while the Jacobian matrix has dimensions of $N \times N$.
%In contrast, for vector problems, like the solid mechanics problems considered in this work, the residual and solution vectors have dimensions of $N_d N \times 1$ and the Jacobian matrix has dimensions of $N_d N \times N_d N$, where $N_d$ is the geometric dimension of the problem, e.g. $N_d = 2$ for 2-D and $N_d = 3$ for 3-D.
The components of the $N \times N$ Jacobian are
\begin{eqnarray} \label{eq:J}
	{J}_{ij} = \frac{\partial {R}_i (\bb{u})}{\partial u_j}
\end{eqnarray}

In the current work, we are interested in vector problems, where the governing momentum equation is formulated in terms of the unknown displacement solution vector.
In this case, Equation \ref{eq:J} refers to the individual scalar components of the residual, solution, and Jacobian.
That is, for 3-D analyses, the residual takes the form
\begin{eqnarray}
	\bb{R}(\bb{u}) = \left\{ R_1^x, R_1^y, R_1^z, R_2^x, R_2^y, R_2^z, ..., R_n^z \right\}
\end{eqnarray}
and the solution takes the form
\begin{eqnarray}
	\bb{u} = \left\{ u_1^x, u_1^y, u_1^z, u_2^x, u_2^y, u_2^z, ..., u_n^z \right\}
\end{eqnarray}
In practice, it is often more practical and efficient to form and store the residual, solution and Jacobian in a \emph{blocked} manner, where the residual and solution can be considered as vectors of vectors.
Similarly, the Jacobian can be formed in terms of sub-matrix block coefficients.

In the strict Newton procedure, the residuals converge at a quadratic rate when the current solution is close to the true solution; that is, the iteration error decreases proportionally to the square of the error at the previous iteration.
Once the method gets sufficiently close to the true solution, the number of correct digits in the approximation roughly doubles with each iteration. 
However, quadratic convergence is only possible when using the exact Jacobian.
In contrast, a quasi-Newton method uses an approximation to the Jacobian, sacrificing strict quadratic convergence in an attempt to produce an overall more computationally efficient procedure.
From this perspective, the segregated solution algorithm commonly employed in finite volume solid mechanics can be viewed as a quasi-Newton method, where an approximate Jacobian replaces the exact Jacobian: 
\begin{eqnarray} \label{eq:Seg}
    \bb{\tilde{J}}(\bb{u}_k) \;\delta \bb{u} = -\bb{R}(\bb{u}_k)
\end{eqnarray}
In this case, the approximate Jacobian $\bb{\tilde{J}}$ comes from the compact stencil discretisation of a simple diffusion (Laplacian) term.
A benefit of this approach is that the inter-component coupling is removed from the Jacobian, allowing the solution of three smaller scalar systems rather than one larger vector system in 3-D (or two smaller systems in 2-D).

A fully explicit procedure can also be viewed from this perspective by selecting an approximate Jacobian which is diagonal $\bb{\tilde{D}}$, making solution of the linear system trivial:
\begin{eqnarray} \label{eq:exp}
    \bb{\tilde{D}}(\bb{u}_k) \;\delta \bb{u} = -\bb{R}(\bb{u}_k)
\end{eqnarray}


%%--------------------------------------------------------------------------------------------------------------------%%
\subsection{Cell-Centred Finite Volume Discretisation}
\label{sec:discretisation}
%%--------------------------------------------------------------------------------------------------------------------%%
In this work, a nominally second-order cell-centred finite volume discretisation is employed, as described previously, for example, \citep{Cardiff2017, batistic2022, tukovic2013, jasak2000}.
Consequently, only a summary of the discretisation is presented below.

The solution domain is discretised in both space and time.
The total simulation period is divided into a finite number of time increments, denoted as $\Delta t$, and the discretised governing momentum equation is solved iteratively in a time-marching fashion. The spatial domain is partitioned into a finite number of contiguous convex polyhedral cells.
%The proposed solution discretisation follows closely the approach of \citet{cardiff_lagrangian_2017}; consequently, only an overview of the final discretised form of equations and adopted solution algorithm are given below.

The conservation equation (Equations \ref{eqn:momentum_lingeom}, \ref{eqn:momentum_TL}, or \ref{eqn:momentum_UL}) is applied to each cell (control volume) in the computational mesh and discretised in terms of the displacement at the cell centre/centroid $\bb{u}_P$ and at the centres of the neighbouring cells $N_i$.

To complete the discretisation, the volume integrals and surface integrals in the governing equation must be approximated by algebraic equations.
Starting first with the volume integrals, assuming a linear variation of the integrand, the mid-point rule approximates the integral in terms of the cell centre value.
Consequently, the inertia term (e.g. left-hand side term of Equation \ref{eqn:momentum_lingeom}) becomes
\begin{eqnarray} \label{eq:inertia}
	\int_{\mathrm{\Omega}} \rho \frac{\partial \bb{u} }{\partial t}  d\mathrm{\Omega}
	\;&\approx&\;
	\rho_P \left(\frac{\partial^2 \bb{u} }{\partial t^2}\right)_P  \Omega_P
\end{eqnarray}
and, similarly, the body force term (e.g. the second term on the right-hand side of Equation \ref{eqn:momentum_lingeom}) becomes:
\begin{eqnarray}
	\int_{\mathrm{\Omega}} \, \rho \, \bb{g} \,  d\mathrm{\Omega}
	\;&\approx&\;
	\rho_P \, \bb{g}\,  \Omega_P
\end{eqnarray}
where subscript $P$ indicates a quantity at the cell centre.
The discretisation of the acceleration in time in Equation \ref{eq:inertia} can be achieved using the finite difference method, e.g. first-order Euler, second-order backwards, second-order Newmark-beta.
\hl{Maybe we should give the temporal discretisation for completeness: i.e. 2nd order backwards}

The surface integral term (e.g. first term on the right-hand side of Equation \ref{eqn:momentum_lingeom}), corresponding to the divergence of stress, is discretised by assuming that the stress varies linearly across the face, allowing the mid-point rule to be used:
\begin{equation}
	\oint_{\Gamma} \bb{n} \cdot \bb{\sigma}  \; d\Gamma
	\approx 
	\sum_{f \in N_f} \bb{\Gamma}_{f} \cdot \bb{\sigma}_f
\end{equation}
where subscript $f$ indicates a quantity at the centre of a cell face, and $N_f$ represents the set of neighbouring cells which share a face with cell $P$.
The stress at a face, $\bb{\sigma}_f$, is calculated by linearly interpolating from the adjacent cell centres.
Stress is calculated at the cell centres as a function of the displacement gradient, $\left(\bb{\nabla}\bb{u}\right)_f$, and the cell-centre gradients are determined using a least squares method \cite{noauthor_openfoam_2015}.

The discretisation is complete but, in its current form, is known to suffer from zero-energy modes, i.e. checkerboarding oscillations.
Here, a Rhie-Chow-type stabilisation term \cite{Rhie1983} is added to the residual (Equation \ref{eqn:residual}) to quell such oscillations.
The Rhie-Chow stabilisation term, first used for finite volume solid mechanics by  \citet{Demirdzic1995}, consists of the numerical difference between a diffusion (Laplacian) term calculated using compact and larger computational stencils.
The term introduces numerical diffusion to the discretisation, which reduces at a third-order rate.
% based on the earlier approach of Rhie and Chow \citet{demirdzic_numerical_1995}.
%One issue encountered with the finite volume method is that the discretisation of the governing conservation of momentum equation ( can be unstable and is known to suffer from checker-boarding errors .
%In order to rectify these issues, the Rhie-Chow stabilisation term \cite{rhie_numerical_1983} as introduced into solid mechanics by  is added to the discretised divergence of the stress in equation \ref{eqn:MomentumImplicitExplicit}.
In the current approach, the Rhie-Chow stabilisation term $\mathcal{D}_{\text {Rhie-Chow }}$ for a cell $P$ takes the following form:
\begin{equation} \label{eq:RhieChow}
	\mathcal{D}_{\text {Rhie-Chow}}
	= \sum_{f \in N_f} \alpha \bar{K}_f
	\left[
	\left|\bb{\Delta}_f\right| \frac{ \bb{u}_{N_f} - \bb{u}_P}{\left|\bb{d}_f\right|}
	- \bb{\Delta}_f \cdot \left(\bb{\nabla} \bb{u} \right)_f
	\right]
	\left|\bb{\Gamma}_{f}\right| 
\end{equation}
%which comes from the difference between Equations \ref{eq:diffusion} and \ref{eq:diffusion_exp}.
where $\alpha > 0$ is a user-defined parameter for globally scaling the amount of stabilisation.
Parameter $\bar{K}_f$ is a stiffness-type parameter that gives the stabilisation an appropriate scale and dimension.
Here, $\bar{K}_f = \frac{4}{3}\mu + \kappa = 2\mu + \lambda$ following previous work \cite{Jasak2008, Cardiff, etc}, where $\mu$ is the shear modulus (first Lam\'{e} parameter), $\kappa$ is the bulk modulus, and $\lambda$ is the second Lam\'{e} parameter.
%where $N_f$ represents the set of faces $f$ in cell $P$, and neighbouring cell centre $N_f$ shares face $f$ with the cell $P$.
Vector $\bb{d}_{f}$ connects cell centre $P$ with the other cell sharing face $f$, and $\bb{n}_{f}$ is the outward-facing unit normal to the face $f$.
The vector $\bb{\Delta}_{f} = \frac{\bb{d}_{f}}{\bb{d}_{f} \cdot \bb{n}_{f}}$ is termed the \emph{over-relaxed orthogonal} vector \cite{Jasak1996} and increases in magnitude as the deviation between the $\bb{d}_{f}$ and $\bb{n}_{f}$ vectors increases.
In this way, the amount of stabilisation increases on distorted meshes.
\hl{Should we mention Nishikawa alpha scheme?} \hl{Very similar: but scales differently with mesh distortion}
%and non-orthogonal correction vector $\bb{k}_f=\bb{n}_f-\bb{\Delta}_f$, where $\bb{n}_f$ is the outward-facing unit normal to the face $f$.
%Vector $\bb{d}_f$ connects the centre of cell $P$ with the centre of cell $N_f$ in the updated configuration.
%The first term on the right-hand side is treated implicitly, while the second term - representing non-orthogonal corrections at the face - is treated in a deferred correction manner.

In Equation \ref{eq:RhieChow}, the first term within the brackets on the right-hand side represents a compact stencil (two-node) approximation of the face normal gradient, while the second term represents a larger stencil approximation.
These two terms cancel out in the limit of mesh refinement (or if the solution varies linearly); otherwise, they produce a stabilisation effect that tends to smooth the solution fields.
As the term reduces at a third-order rate, it does not affect the overall scheme's second-order accuracy.

All dependent variables must be specified at the initial time.
Boundary conditions must be applied to the faces that coincide with the boundary of the solution domain.
The discretised expressions on boundary faces are modified to account for either the known displacement components in Dirichlet conditions or the known traction for Neumann conditions.



\hl{Comment on traction boundaries} \hl{extrapolate to get value or use constitutive law}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Solution Algorithms}\label{sec:sol_alg}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%- Seg approach summary
%- JFNK approach summary
%	- implementation via PETSc. Newton with line search, GMRes with MG preconditioner.

%%--------------------------------------------------------------------------------------------------------------------%%
\subsection{Segregated Solution Algorithm} 
\label{sec:seg_alg}
%%--------------------------------------------------------------------------------------------------------------------%%
The classic segregated solution algorithm can be viewed as a quasi-Newton method, where a compact-stencil approximation of a diffusion term is employed as the approximate Jacobian:
%The surface forces Laplacian term (first term on the right-hand side of Equation \ref{eqn:MomentumImplicitExplicit}) is discretised using central differencing with over-relaxed non-orthogonal correction \cite{demirdzic_finite_1993, jasak_application_2000, cardiff_development_2014, cardiff_large_2014, cardiff_lagrangian_2017}:
\begin{eqnarray} \label{eq:diffusion}
	\tilde{\bb{J}} &=& \oint_{\Gamma} \bar{K} \, \bb{n} \cdot \bb{\nabla} \bb{u} \; d\Gamma \notag \\
	&\approx&
	\sum_{f \in N_f} \bar{K}_f \left|\bb{\Delta}_f\right| \left(\frac{\bb{u}_{N_f} - \bb{u}_P}{\left|\bb{d}_f\right|}\right)\left|\bb{\Gamma}_f\right|
%	    &&+ \sum_{f \in N_f} \bar{K}_f \; \bb{k}_f \cdot  \left( \bb{\nabla} \bb{u}\right)_f    \left|\bb{\Gamma}_f\right|
\end{eqnarray}
%where $N_f$ represents the set of faces $f$ in cell $P$, and neighbouring cell centre $N_f$ shares face $f$ with the cell $P$.
%The over-relaxed orthogonal vector $\bb{\Delta}_f = \frac{\bb{d}_f}{\bb{d}_f \cdot \bb{n}_f}$ 
%The non-orthogonal correction vector $\bb{k}_f=\bb{n}_f-\bb{\Delta}_f$.
% where $\bb{n}_f$ is the outward-facing unit normal to the face $f$.
%Vector $\bb{d}_f$ connects the centre of cell $P$ with the centre of cell $N_f$ in the updated configuration.
%The first term on the right-hand side is treated implicitly, while the second term - representing non-orthogonal corrections at the face - is treated in a deferred correction manner.
When a diffusion term is typically discretised using the cell-centre finite volume method, non-orthogonal corrections are included in a deferred correction manner to preserve the order of accuracy on distorted grids.
However, in the Newton method case, the approximate Jacobian's exact value does not affect the final converged solution, but only the convergence behaviour.
Consequently, non-orthogonal corrections are not included in the approximate Jacobian here. However, grid distortion is appropriately accounted for in the calculation of the residual.
Nonetheless, as a result, it is expected that the convergence behaviour of the segregated approach may degrade as mesh non-orthogonality increases.
% since their implicit inclusion would require a coupled solution approach

The linearised system (Equation \ref{eq:Seg}) is formed for each cell in the domain, resulting in a system of algebraic equations:
\begin{eqnarray} \label{eq:SegSys}
    \bb{\tilde{J}}(\bb{u}_n) \; \delta \bb{u} = - \bb{R}(\bb{u}_n)
\end{eqnarray}
where $\bb{\tilde{J}}$ is a symmetric, weakly diagonally dominant, $M \times M$ stiffness matrix, where $M$ is three times the number of cells in 3-D and twice the number of cells in 2-D.
By design, matrix $\bb{\tilde{J}}$  contains no inter-component coupling; consequently, three equivalent smaller linear systems can be formed and solved for the Cartesian components of the displacement correction (or two in 2-D), e.g.
\begin{eqnarray} \label{eq:SegSysX}
     \bb{\tilde{J}}_x(\bb{u}_n)  \;  \Delta \bb{u}_x = - \mathcal{R}_x(\bb{u}_n) \label{eq:segX} \\
     \bb{\tilde{J}}_y(\bb{u}_n)  \;  \Delta \bb{u}_y = - \mathcal{R}_y(\bb{u}_n) \label{eq:segY} \\
     \bb{\tilde{J}}_z(\bb{u}_n)  \;  \Delta \bb{u}_z = - \mathcal{R}_z(\bb{u}_n) \label{eq:segZ}
\end{eqnarray}
where $ \bullet_x$ represents the components in the $x$ direction, $ \bullet_y$ represents the components in the $y$ direction, and $ \bullet_z$ represents the components in the $z$ direction.
An additional benefit of the segregated approach, from a memory perspective, is that matrices $ \bb{\tilde{J}}_x$, $ \bb{\tilde{J}}_y$ and $\bb{\tilde{J}}_z$ are identical, except for the effects from including boundary conditions.
From an implementation perspective, this allows a single scalar matrix to be formed and stored, where the boundary condition contributions are inserted before solving a particular component.

The \emph{inner} linear sparse systems (Equations \ref{eq:segX}, \ref{eq:segY} and \ref{eq:segZ}) can be solved using any typical direct or iterative linear solver approach; however, an incomplete Cholesky pre-conditioned conjugate gradient method \cite{Jacobs1986} is often preferred as the weakly diagonally dominant characteristic leads to good convergence characteristics.
Algebraic multigrid can be used to accelerate convergence.
%In non-linear problems, this system of equations is solved multiple times with updated coefficients in a fixed-point iteration scheme. 
%As noted in previous articles on segregated methods, the inner system need not be solved to a tight tolerance as coefficients and source terms are approximated from the previous increment; a reduction in the residuals of one order of magnitude is typically sufficient. The outer iterations are performed until the predefined tolerance, typically $1 \times 10^{-6}$, has been achieved \cite{cardiff_lagrangian_2017}. 
%In the current updated Lagrangian approach, the mesh is moved to the deformed configuration at the end of each time step rather than after each outer iteration.
%Since the displacements are calculated at the cell centres, a linear least-squared method is employed here \cite{cardiff_lagrangian_2017} to interpolate the displacement increments to the mesh vertices, allowing the mesh to be moved.
%In this method, a linear least squares plane is fit through a vertex and its immediately adjacent cell centres. For boundary vertices, boundary face-centre values are also included in the fitting.
%
%The procedures have been implemented and publicly shared within the solids4foam toolbox \citep{Cardiff2018, Tukovic2018} of the open-source OpenFOAM software.

In literature, the segregated solution algorithm is typically formulated in terms of the total displacement vector (or its difference between time steps) as the primary unknown; in contrast, in the quasi-Newton interpretation presented here, the primary unknown is the correction to the displacement vector, which goes to zero at convergence.
Nonetheless, both approaches are equivalent and neither formulation displays superior performance.

The current procedure is implemented and publicly shared in the solids4foam toolbox of OpenFOAM.
\hl{Add a section about code sharing: appendix?}

\hl{Comment: we have two implementations of segregated: native OpenFOAM (solves Eqs 16-18) and PETSc SNES (solves Eq 15)}
\hl{Do we need to comment on this? Maybe we should use only PETSc SNES for a fair comparison}
\hl{Or we could use both on the verification case and then stick with just one afterwards}



%%--------------------------------------------------------------------------------------------------------------------%%
\subsection{Jacobian-free Newton-Krylov Algorithm}
\label{sec:JFNK_alg}
%%--------------------------------------------------------------------------------------------------------------------%%

%\hl{cite KnollKeyes2004}

As noted in the introduction, the Jacobian-free Newton-Krylov avoids the need to construct the Jacobian matrix explicitly by approximating its action on a solution vector using the finite difference method, repeated here:
\begin{eqnarray} \label{eq:JF}
	\bb{J} \bb{v} \approx \frac{\bb{F}(\bb{x} + \epsilon \bb{v}) - \bb{F}(\bb{x})}{\epsilon}
\end{eqnarray}

%\hl{1}
%Derive Jv for 2x2 system.
The derivation of this approximation can be shown for a $2 \times 2$ system as \cite{Knoll2004}:
\begin{eqnarray}
	\frac{\mathbf{F}(\mathbf{x} + \epsilon \mathbf{v}) - \mathbf{F}(\mathbf{x})}{\epsilon}
	&=&
	\begin{pmatrix}
	\frac{F_1 (x_1 + \epsilon v_1, x_2 + \epsilon v_2) - F_1 (x_1, x_2)}{\epsilon}\\
	\frac{F_2 (x_1 + \epsilon v_1, x_2 + \epsilon v_2) - F_2 (x_1, x_2)}{\epsilon}
	\end{pmatrix} \notag \\
	&\approx&
	\begin{pmatrix}
	\frac{F_1 (x_1,x_2) + \epsilon v_1 \frac{\partial F_1}{\partial u_1} + \epsilon v_2 \frac{\partial F_1}{\partial u_2} - F_1 (x_1, x_2)}{\epsilon}\\
	\frac{F_2 (x_1, x_2) + \epsilon v_1 \frac{\partial F_2}{\partial u_1} + \epsilon v_2 \frac{\partial F_2}{\partial u_2}  - F_2 (x_1, x_2)}{\epsilon}
	\end{pmatrix} \notag \\
	&\approx&
	\begin{pmatrix}
	v_1 \frac{\partial F_1}{\partial u_1} +  v_2 \frac{\partial F_1}{\partial u_2} \\
	v_1 \frac{\partial F_2}{\partial u_1} + v_2 \frac{\partial F_2}{\partial u_2}
	\end{pmatrix} \notag \\
	&\approx&
	\bb{J} \bb{v}
\end{eqnarray}
where a first-order truncated Taylor series expansion about $\bb{u}$ was used to approximate $\bb{F} (\bb{x} + \epsilon \bb{v})$.
%\hl{1b}
%Choosing $\epsilon$ is important.
As noted above, choosing an appropriate value for $\epsilon$ is non-trivial, and care must be taken to balance truncation error (reduced by decreasing $\epsilon$) and round-off error (increased by decreasing $\epsilon$).


%\hl{2}
%- preconditioner => important
%- changes the JFNK approx.
%- precon affects the JF approx

%The literature indicates that the choice of preconditioner for the inner linearised system has a major impact on the efficiency and robustness of the overall solution procedure.
The purpose of preconditioning the Jacobian-free Newton-Krylov method is to reduce the number of inner linear solver iterations.
In the current work, the GMRES linear solver is used for the inner system.
%Left or right preconditioning, may be employed in a Jacobian-free context, and there are pros and cons to both.
Using right preconditioning, the finite difference approximation of Equation \ref{eq:JF} becomes
\begin{eqnarray}
%	(\bb{J} \bb{P}^{-1}) (\bb{P} \delta \bb{u}) = -\bb{R}(\bb{u})
	\bb{J} \bb{P}^{-1} \bb{v}
	\approx
	\frac{\bb{F}(\bb{x} + \epsilon \bb{P}^{-1} \bb{v}) - \bb{F}(\bb{x})}{\epsilon}
\end{eqnarray}
where $\bb{P}$ is the preconditioning matrix or process.
In practice, only the action of $\bb{P}^{-1}$ on a vector is required, and the $\bb{P}^{-1}$ may not be explicitly formed.
Concretely, the preconditioner needs to approximately solve the linear system $\bb{y} = \bb{P}^{-1} \bb{v}$.
%Thus, while we may refer to the matrix P, operationally the algorithm only requires the action of $P^{-1}$ on a vector.

%\hl{3}
%- we use approx J to form precon
%- many precon used in lit, we will consider ILU(N) and MG, where MG is expected to be better, but also LU since direct solvers are popular in FE solid mechanics
In the current work, we proposed to use the compact-stencil approximate Jacobian from the segregated algorithm $\tilde{\bb{J}}$ as the preconditioning matrix $\bb{P}$ for the preconditioned Jacobian-free Newton-Krylov method.
\hl{Comment on literature: used before but not yet for solids}.
This preconditioning approach can be considered as a ``physics-based" preconditioner in the classifications of \cite{Knoll2004}.
The approach is conceptually similar to an approximation of the Jacobian of a higher-order advection scheme by a compact-stencil lower-order upwind scheme.
A benefit of the proposed approach is that existing segregated frameworks can re-use their existing discretisation and storage implementations.
Concretely, the Jacobian-free Newton-Krylov method requires only a procedure for forming this preconditioning matrix and a procedure for explicitly evaluating the residual.
Both routines are easily implemented in an existing segregated framework.
The only additional required procedure is an interface to an existing Jacobian-free Newton-Krylov implementation.
%"The motivation behind this approach is that there exist numerous, legacy algorithms to solve nonlinear systems, both IVPs and BVPs. These algorithms typically were developed with some insight into the time scales or physical behavior of the problem. As a benefit of this insight, a reduced implicit system, or a sequence of segregated explicit or implicit systems may be solved in place of the fully coupled system. "
In the current work, the PETSc toolbox \cite{PETSc} is used as the nonlinear solver, where driven by a finite volume solver in the OpenFOAM toolbox \cite{OF}.

Several preconditioners are available in the literature, incomplete Cholesky/LU being popular; however, multigrid methods offer the greatest potential for large-scale problems.
\citet{Knoll2004} noted that algorithmic simplifications within a multigrid procedure, which may result in loss of convergence for multigrid as a solver, have a much weaker effect when multigrid is the preconditioner.
In this work, three preconditioners are considered:
\begin{enumerate}
	\item ILU(N): incomplete LU with fill-in $N$. The segregated solver uses ILU(0), that is, ILU with zero fill-in.
	\item Multigrid: here, we use the HYPRE Boomerang multigrid implementation.
	\item LU: for comparison, we consider a direct LU decomposition solver as the preconditioner.
\end{enumerate}


%\hl{4 - globalisation}
A challenge with Newton-type methods, including Jacobian-free versions, is convergence can be poor when far from the true solution, and divergence is often a real possibility.
Globalisation refers to steering an initial solution towards the quadratic convergence range of the Newton method.
Several strategies are possible, and it is common to combine approaches \cite{Knoll2004}.
In the current work, a line search procedure is used to select the $s$ parameter in the solution update step (the second line in Equations \ref{eq:NewtonRaphson}).
Line search methods assume the Newton update direction is correction and aim to find a scalar $s > 0$ that decreases the residual $\bb{R}(\bb{u}_k + s \delta \bb{u}) < \bb{R}(\bb{u}_k)$.
The scalar $s$ is typically $\leq 1$, but extrapolation ($>1$) is also possible for accelerating convergence, albeit at the expense of robustness.

In addition to a line search approach, a \emph{transient continuation} globalisation approach is used in the current work, where a prediction for the solution (displacement) field at time $t + \Delta t$ is performed at the start of a new time step, based on a truncated second-order Taylor series expansion:
\begin{eqnarray} \label{eq:predictor}
	\bb{u}_{t+\Delta t} = \bb{u}_t + \Delta t \left(\frac{\partial \bb{u}}{\partial t}\right)_t + \frac{1}{2} \Delta t^2 \left( \frac{\partial^2 \bb{u}}{\partial t^2} \right)_t
\end{eqnarray}
where $\Delta t$ is the time increment (assumed constant here), $\left(\frac{\partial \bb{u}}{\partial t}\right)_t$ is the velocity at time $t$, and $\left( \frac{\partial^2 \bb{u}}{\partial t^2} \right)_t$ is the acceleration at time $t$.
In this way, for highly nonlinear problems, the user can decrease the time step size $\Delta t$ as a globalisation approach to improve the performance of the Newton method.
The predictor step in Equation \ref{eq:predictor} has been chosen to be consistent with the assumed discretisation of the temporal term in the governing equation; that is, the second order backwards scheme is assumed.


%\hl{5 - oversolving}
%Comment on over-solving => also applies to the segregated system.
%This could be a parameter we look at.
A final comment on the Jacobian-free Newton-Krylov solution algorithm is the potential importance of \emph{oversolving}.
Here, oversolving refers to solving the linear system to too tight a tolerance during the early Newton iterations, essentially wasting time when the solution is far from the true solution.
In addition, some authors %\cite{See164_and_176_in_Knoll2004}
\cite{Knoll2004} have shown Newton convergence to be worse when the earlier iterations are solved to too tight a tolerance.
The concept of oversolving also applies to segregated solution procedures and has been well-known since the early work of Demird\v{z}i\'{c} and co-workers \cite{Demirdzic}, where the residuals are typically reduced by one order of magnitude in the inner linear system.
The optimal choice of residual reduction for a Jacobian-free Newton-Krylov finite volume solid mechanics procedure is explored in Section \ref{sec:test_cases}. \hl{Check: do we examine this?}


%Knoll2004:
%The forcing term and the issue of ‘‘oversolving’’ a Newton step has recently gained interest [164,176]. The concept of ‘‘oversolving’’ implies that at early Newton iterations c is too small. Then one may obtain an accurate linear solution to an inaccurate Newton correction. This may result in a poor Newton update and degradation in the Newton convergence. In [164,176] it has been demonstrated that in some situations the Newton convergence may actually suffer if c is too small in early Newton iterations.




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Test Cases}\label{sec:test_cases}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%Cases
%Focus on times, rather than accuracy => same discretisation error and seg already verified.
% What features do I want to examine?
% 2-D and 3-D
% Meshes: structured vs unstructured (tet but poly would be cool)
% NLGeom: small vs large strains
% material: elasticity vs other physics, e.g. elastoplasticity
% transient vs static
% parallel scaling
% BCs types:
% 	- NOT contact or cracks or other nonlinear BCS
%	- disp, traction, symmetry

% Possible cases
% Compare seg and JFNK; maybe also Abaqus, just for reference
% Show times/results for successively refined meshes
%- cantilever -> dynamic 3-D from Zeljko paper
%- narrowTmember
%- ellipticPlate
%- spherical cavity - uniaxial, static
%- spherical cavity - dynamic, pressure
%- Other
%	- cooks membrane (small or large strain)
%	- necking -> Andrew's flatBar 3-D case, maybe even with his damage model?
%	- bi-material
%	- industrial case: bad/real mesh and show parallel scaling
%	- ideal ventricle (problem 2, Land et al.)
%	
%Effects that could be studied:
%- stabilisation magnitude (scaleFactor with RhieChow or alpha)
%- globalisation strategies, e.g. predictor, segregated solution, time-step, composite snes
%- parallel scaling
%- preconditioner: LU, ILU (what N?), MG (HYPRE) and linear solver
%  	- Knoll found that lagging the precondioner construction gave speed-ups: this is easy for us to try with PETSc
%	- effect of GMRES "restart": Knoll shows that lower restarts can be used with a better preconditioner
%- mesh types: uniform mesh vs large gradients in refinement; structured vs unstructured

This section assesses the performance of the proposed Jacobian-free Newton-Krylov solution approach on several benchmark cases.
The cases have been chosen to exhibit a variety of characteristics in terms of
\begin{itemize}
	\item Geometric dimension (2-D vs. 3-D),
	\item Geometric nonlinearity (small strain vs. large strain)
	\item Statics vs. dynamics, and
	\item Material behaviour (elasticity, elastoplasticity, hyperelasticity).
\end{itemize}

In addition, through the analysis of the benchmark cases above, the effect of several parameters will be examined, including the mesh types, Rhie-Chow stabilisation scaling, preconditioner choices, linear solver settings, the effect of globalisation strategies, and multi-CPU-core parallelisation.
The performance of the Jacobian-free Newton-Krylov algorithm is compared with that of the segregated algorithm in terms of computational time and memory requirements.
Metrics from a commercial finite element software (Abaqus) are included for reference \hl{ask Dylan to run Abaqus cases once we have our results}.

The presented analyses aim to be extensive but not exhaustive.
Several common features of modern solid mechanics procedures are left for future work, including contact mechanics and incompressibility. %, where mixed formulations are required. 

The remainder of this section is structured as follows:
the order of accuracy of the proposed discretisation is assessed on a 3-D linear elastic case with a known analytical solution.
This demonstrates that the predictions are unaffected by the solution algorithm choice.
Subsequently, the remaining sub-sections assess the effect of several key parameters on the Jacobian-free Newton Krylov approach, including \hl{XXX}.


%%--------------------------------------------------------------------------------------------------------------------%%
\subsection{Description of the Selected Benchmark Cases}
\label{sec:case_descriptions}
%%--------------------------------------------------------------------------------------------------------------------%%

%\hl{Here, for the selected 4-6 cases, we should describe:}
%\hl{- geometry (+ image) and meshes (maybe image of one type of mesh)}
%\hl{- material properties}
%\hl{- loading conditions}
%\hl{I suggest we aim to keep the descriptions above concise}
%\hl{we can use tables where appropriate and can include the loading conditions in the geometry figure}

This section concisely describes the benchmark cases examined in subsequent sections.
Details of the geometry, mesh, loading conditions, material properties, and relevant numerical settings are given so that the results can be reproduced.
\hl{We may need to drop some of these cases if we have too many: cases 2 and 3 are very similar (3-D, static, linear elastic)}
 
\paragraph{Case 1: Order Verification via the Manufactured Solution Procedure}
The first test case consists of a $0.2 \times 0.2 \times 0.2$ m cube with linear elastic ($E = 200$ GPa, $\nu = 0.3$) properties.
A manufactured solution for displacement (Figure \ref{fig:mms_solution}) is employed of the form:
\begin{eqnarray}
	\bb{u} =
	\begin{pmatrix}
	a_x \sin(4\pi x) \sin(2\pi y) \sin(\pi z) \\
	a_y \sin(4 \pi x) \sin(2 \pi y) \sin(\pi z) \\
	a_z \sin(4 \pi x) \sin(2 \pi y) \sin(\pi z) 
	\end{pmatrix}
\end{eqnarray}
where $a_x = 2\times10^{-6}$ m, $a_y = 4\times10^{-6}$ m, and $a_z = 6\times10^{-6}$ m.
The Cartesian coordinates are given by $x$, $y$ and $z$.
The resulting body force to force the manufactured solution is given in Appendix \ref{app:mms}.
%\begin{figure}[htbp]
%   \centering
%   \includegraphics[width=0.5\textwidth]{figures/mms_solution} 
%   \caption{Cut plane through the cube case geometry showing the magnitude of the manufactured displacement solution. The cut plane passes through the centre of the cube and has the unit normal $\bb{n} = (\sfrac{1}{\sqrt{3}} \quad \sfrac{1}{\sqrt{3}} \quad \sfrac{1}{\sqrt{3}})$.}
%   \label{fig:mms_solution}
%\end{figure}
\begin{figure}[htbp]
	\centering
	\subfigure[Magnitude of the manufactured displacement solution]
	{
		\label{fig:mms_solution}
   		\includegraphics[height=0.45\textwidth]{figures/mms_solution} 
   	}
	\subfigure[Polyhedral mesh with $1\,000$ cells]
	{
		\label{fig:mms_mesh}
   		\includegraphics[height=0.45\textwidth]{figures/mms_mesh}  
   	}
	\caption{A cut plane through the cube case geometry showing the magnitude of the manufactured displacement solution (left) and a polyhedral mesh (right). The cut plane passes through the centre of the cube and has the unit normal $\bb{n} = (\sfrac{1}{\sqrt{3}} \quad \sfrac{1}{\sqrt{3}} \quad \sfrac{1}{\sqrt{3}})$.}
	\label{fig:mms}
\end{figure}

The manufactured displacement solution is applied at the domain's boundaries, and inertial effects are neglected.
Two forms of mesh are examined: (i) structured, uniform hexahedra and (ii) regular polyhedra (Figure \ref{fig:mms_mesh}).
To create the polyhedral meshes, structured tetrahedra meshes are first generated using Gmsh \cite{Geuzaine2009} and then converted to their dual polyhedral representations using the OpenFOAM \texttt{polyDualMesh} utility.
Starting from an initial mesh spacing of $0.04$ m, six meshes are created by successively halving the spacing.
The cell numbers (hexahedra and polyhedral meshes) are 125, $1\,000$, $8\,000$, $64\,000$, $512\,000$, and $4\,096\,000$.


\paragraph{Case 1b: Spherical Cavity in an Infinite Solid Subjected to Remote Stress}
This 3-D case consists of a spherical cavity with radius $a = 0.2$ m (Figure \ref{fig:spherical_cavity}) in an infinite, isotropic linear elastic solid ($E = 200$ GPa, $\nu = 0.3$).
Far from the cavity, the solid is subjected to a tensile stress $\sigma_{zz} = T = 1$ MPa, with all other stress components zero.
\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.4\textwidth]{figures/spherical_cavity.pdf} 
   \caption{Spherical cavity case geometry, showing the polyhedral mesh with 2,257 cells \hl{Update to graded mesh}}
   \label{fig:spherical_cavity}
\end{figure}
The analytical expressions for the stress distributions around the cavity, first derived by \cite{Southwell1926}, are
\begin{eqnarray}
	\sigma_{rr} &=&
		\frac{T}{14 - 10\nu} \frac{a^3}{R^3}
		\left[ 9 - 15\nu - 12 \frac{a^2}{R^2}  - \frac{r^2}{R^2} \left( 72 - 15\nu - 105 \frac{a^2}{R^2} \right) + 15 \frac{r^4}{R^4} \left( 5 - 7 \frac{a^2}{R^2} \right) \right], \\
	\sigma_{\theta\theta} &=&
		\frac{T}{14 - 10\nu} \frac{a^3}{R^3}
		\left[ 9 - 15\nu - 12 \frac{a^2}{R^2}  - 15 \frac{r^2}{R^2} \left( 1 - 2\nu - \frac{a^2}{R^2} \right) \right], \\
	\sigma_{zz} &=&
		T \left[ 1 - \frac{1}{14 - 10\nu} \frac{a^3}{R^3} \left\{ 38 - 10\nu - 24 \frac{a^2}{R^2} 
		- \frac{r^2}{R^2} \left( 117 - 15\nu - 120 \frac{a^2}{R^2} \right)
		+ 15 \frac{r^4}{R^4} \left( 5 - 7 \frac{a^2}{R^2} \right) \right\} \right], \notag \\
		\\
	\sigma_{zr} &=&
	\frac{T}{14 - 10\nu} \frac{a^3 z r}{R^5}
	\left[ -3(19 - 5\nu) + 60 \frac{a^2}{R^2} + 15 \frac{r^2}{R^2} \left( 5 - 7 \frac{a^2}{R^2} \right)  \right].
\end{eqnarray}
where $r^2 = x^2 + y^2$ is the cylinderical radial coordinate, $R^2 = r^2 + z^2$ is the spherical radial coodinate, and $x$, $y$, $z$ are the Cartesian coordinates.

\hl{Philip please double check added displacement equations from Goodier}
\begin{eqnarray}
u_r &=& -\frac{A}{r^2} - \frac{3B}{r^4} + \left[ \frac{5-4\nu}{1-2\nu} \frac{C}{r^2}-9\frac{B}{r^4} \right]\cos (2\theta),\\
u_{\theta} &=& - \left[ \frac{2C}{r^2} + 6\frac{B}{r^4}  \right]\sin(2\theta),
\end{eqnarray}
where $A$, $B$ and $C$ constants are defined as follows:
\begin{equation}
\frac{A}{a^3} = -\frac{T}{8\mu}\frac{13-10\nu}{7-5\nu}, \qquad
\frac{B}{a^5} = -\frac{T}{8\mu}\frac{1}{7-5\nu}, \qquad
\frac{C}{a^3} = -\frac{T}{8\mu}\frac{5(1-2\nu)}{7-5\nu}.
\end{equation}


\hl{We can move the analytical solutions to an appendix}

The solution domain is taken as one-eighth of a $1 \times 1 \times 1$ m cube centred on the sphere.
The analytical tractions are applied at the far boundaries of the domain to mitigate the effects of finite geometry.
Unstructured polyhedral meshes of varying densities are employed (\hl{state average cell widths, and number of cells in each mesh}).
The mesh with 2,257 cells is shown in Figure \ref{fig:spherical_cavity}.
Initially, unstructured tetrahedral meshes were generated using the Gmsh meshing utility \cite{Geuzaine2009}, followed by conversion to their dual polyhedral representations using the OpenFOAM \texttt{polyDualMesh} utility.


\paragraph{Case 2: Out-of-plane bending of an elliptic plate}
This 3-D, static, linear elastic test case (Figure \ref{fig:elliptic_plate}) consists of a thick elliptic plate (0.6 m thick) with a centred elliptic hole, with the inner and outer ellipses given as
\begin{eqnarray}
	\left(\frac{x}{2}\right)^2 + \left(\frac{y}{1}\right)^2 = 1 & \text{inner ellipse} \\
	\left(\frac{x}{3.25}\right)^2 + \left(\frac{y}{2.75}\right)^2 = 1 & \text{outer ellipse}
\end{eqnarray}
The case has been described by the National Agency for Finite Element Methods and Standards (NAFEMS) \cite{NAFEMS}, and analysed using finite volume procedures by \citet{Demirdzic1997} and \citet{Cardiff2016}.
Symmetry allows one quarter of the geometry to be simulated.
A constant pressure of 1 MPa is applied to the upper surface, and the outer surface is fully clamped.
The mechanical properties are: $E = 210$ GPa, $\nu = 0.3$.
\hl{Comment on the meshes used}.
%\begin{figure}[htbp]
%   \centering
%   %\includegraphics[width=0.2\textwidth]{figures/elliptic_plate.pdf} 
%   \includegraphics[width=0.2\textwidth]{figures/placeholder.pdf} 
%   \caption{Elliptic Plate case geometry, mesh and loading conditions}
%   \label{fig:elliptic_plate}
%\end{figure}
\begin{figure}[H]
	\centering
	\subfigure[Case geometry (considered quarter geometry)]
	{
		\label{fig:eliptic_plate_geometry}
   		\includegraphics[scale=1]{figures/ellipticPlate-geometry} 
   	}
   	\qquad
	\subfigure[Mesh with 1,620 cells]
	{
		\label{fig:eliptic_plate_mesh}
   		\includegraphics[scale=0.4]{figures/placeholder.pdf}  
   	}
	\caption{Elliptic Plate case geometry, mesh and loading conditions.}
	\label{fig:elliptic_plate}
\end{figure}

\paragraph{Case 3: Narrow T-section component under tension}
This case, proposed by \citet{Demirdzic1997}, consists of a narrow engineering component with a T cross-section (Figure \ref{fig:narrowTmember}).
The case is 3-D, static, with linear elastic material behaviour.
Symmetry allows one quarter of the geometry to be simulated.
A constant negative pressure of 1 MPa is applied to the lower surface and the upper left surface is fully clamped.
The Young’s modulus is $E = 210$ GPa and Poisson’s ratio is $\nu = 0.3$.
A hole of radius $5$ mm is located at the expected stress concentration.
\hl{Comment on the meshes}
%\begin{figure}[htbp]
%   \centering
%   \includegraphics[width=0.4\textwidth]{figures/narrowTmember-geometry.pdf} 
%   \caption{Inflation of an idealised ventricle case geometry, mesh and loading conditions}
%   \label{fig:narrowTmember}
%\end{figure}
\\
\hl{Philip, so far I have been doing pictures in xfig which is a bit outdated so I am switching to inkscape. I know you have this image of geometry from your article, so feel free to replace it. I made it purely to practice inkscaping.}
\begin{figure}[H]
	\centering
	\subfigure[Case geometry (considered quarter geometry)]
	{
		\label{fig:narrowTmember_geometry}
   		\includegraphics[scale=1]{figures/narrowTmember-geometry} 
   	}
   	\qquad
	\subfigure[Mesh with 1,620 cells]
	{
		\label{fig:narrowTmember_mesh}
   		\includegraphics[height=0.4\textwidth]{figures/placeholder.pdf}  
   	}
	\caption{Narrow T-section component under tension.}
	\label{fig:narrowTmember}
\end{figure}

\paragraph{Case 4: Inflation of an idealised ventricle}
Inflation of an idealised ventricle (Figure \ref{fig:ventricle}) was proposed by \citet{Land2015} as a benchmark problem for cardiac mechanics software.
The case is 3-D, static, with finite hyperelastic strains.
The initial geometry is defined as a truncated ellipsoid:
\begin{eqnarray}
	x = r_s \sin(u) \cos(v), \quad
	y = r_s \sin(u) \sin(v), \quad
	z = r_l \cos(u)
\end{eqnarray}
where on the inner (endocardial) surface $r_s =7$ mm, $r_l = 17$ mm, $u \in \left[-\pi, -\arccos \left( \frac{5}{17} \right) \right]$ and $v \in \left[-\pi, \pi \right]$, while on the outer (epicardial) surface $r_s =10$ mm, $r_l = 20$ mm, $u \in \left[-\pi, -\arccos \left( \frac{5}{20} \right) \right]$ and $v \in \left[-\pi, \pi \right]$.
The base plane $z = 5$ mm is implicitly defined by the ranges for $u$.
%Constitutive parameters: isotropic, 
The hyperelastic material behaviour is decsribed by the transversely isotropic constitutive proposed by \citet{Guccione1995} law, where the parameters $C = 10$ kPa, $b_f = b_t = b_{fs} = 1$.
The chosen parameters produce isotropic behaviour.
A pressure of 10 kPa is applied to the inner surface, and the base plane is fixed.
The geometry is meshed using structured approach and is predominantly composed of hexahedra, with prism cells forming the apex.
Four succesively refined meshes are examined: 1,620 (shown in Figure  \ref{fig:ventricle}), 12,960, 103,680, and 829,440 cells.
%Figure \ref{fig:ventricle} shows the mesh with 1,620 cells (1,512 hexahedra and 108 prisms).
%\begin{figure}[htbp]
%   \centering
%   \includegraphics[width=0.4\textwidth]{figures/ventricle} 
%   \caption{Idealised ventricle case geometry, showing the mesh with 1,620 cells}
%   \label{fig:ventricle}
%\end{figure}
\begin{figure}[H]
	\centering
	\subfigure[Case geometry, vertical cross-section]
	{
		\label{fig:ventricle_geometry}
   		\includegraphics[scale=1]{figures/ventricle-geometry} 
   	}
   	\qquad
	\subfigure[Mesh with 1,620 cells]
	{
		\label{fig:ventricle_mesh}
   		\includegraphics[scale=0.1]{figures/ventricle}  
   	}
	\caption{Idealised ventricle case.}
	\label{fig:ventricle}
\end{figure}


\paragraph{Case 5: Cook's membrane}
Cook's membrane (Figure \ref{fig:cooks_membrane}) is a well-known bending-dominated benchmark case used in linear and non-linear analysis.
In current work, the finite strain elastoplastic version \citep{Simo1992} is considered. \hl{We could also consider the small-strain elastic version if needed}
The 2-D tapered panel (trapezoid) is fixed on one side and subjected to uniform shear traction on the opposite side.
The prescribed shear traction is $\tau = 0.3125$ MPa.
The vertices of the trapezoid (in mm) are (0, 0), (48, 44), (48, 60),  and (0, 44).
There are no body forces, and the problem is solved as statically as 2-D plane strain.
The problem is solved as static, using 30 equally-sized loading increments.
%\begin{figure}[htbp]
%   \centering
%   \includegraphics[width=0.4\textwidth]{figures/cooksMembrane-geometry} 
%   \caption{Cook's membrane case geometry (dimensions in mm) and loading conditions (fixed left, traction $\tau$ applied to right)}
%   \label{fig:cooks_membrane}
%\end{figure}
\begin{figure}[H]
	\centering
	\subfigure[Case geometry and dimensions]
	{
		\label{fig:cooks_membrane_geometry}
   		\includegraphics[scale=1]{figures/cooksMembrane-geometry} 
   	}
   	\qquad
	\subfigure[Hexahedral mesh with 144 cells]
	{
		\label{fig:cooks_membrane_mesh}
   		\includegraphics[scale=0.14]{figures/cooksMembrane-mesh}  
   	}
	\caption{Cook's membrane.}
   \label{fig:cooks_membrane}
\end{figure}

The Young's modulus $E = 206.9$ MPa and Poisson's ratio $\nu=0.29$, with the yield stress $\sigma_y$ given as \citep{Simo1992}
\begin{eqnarray}
	\sigma_y = \sigma_Y + H\bar{\varepsilon}_p + (\sigma_{\infty} - \sigma_Y)(1- e^{-\delta\bar{\varepsilon}_p})
\end{eqnarray}
The plastic yielding parameters are $\sigma_Y = 0.45$ MPa, $\sigma_{\infty} = 0.715$ MPa, $\delta = 16.93$, and $H = 0.12924$ MPa, where the hardening variable $\bar{\varepsilon}_p$ corresponds to equivalent plastic strain.

\newpage
\hl{Define properties for three cases: i, ii and iii}

\renewcommand{\arraystretch}{2}
\begin{table}[h!]
%\resizebox{\textwidth}{!}{
\begin{tabular}{l|l}
i &  $t_y=6.25$ MPa, $E=70$ MPa, $\nu=1/3$ \\ \hline
ii & $t_y=0.0625$ MPa $E=1.0985$ MPa, $\nu=0.3$   \\ \hline
\multicolumn{1}{c|}{\multirow{2}{*}{iii}} & $t_y=0.3125$ MPa $E=206.9$ MPa, $\nu=0.29$, $\sigma_y = \sigma_Y + H\bar{\varepsilon}_p + (\sigma_{\infty} - \sigma_Y)(1- e^{-\delta\bar{\varepsilon}_p})$ \\[-0.5em]
\multicolumn{1}{c|}{} & $\sigma_Y = 0.45$ MPa, $\sigma_{\infty} = 0.715$ MPa, $\delta = 16.93$, $H = 0.12924$ MPa
\end{tabular}%
%}
\end{table}
\renewcommand{\arraystretch}{1}
\noindent
\textbf{Sources for case i:} \cite{Zienkiewicz2000}\\
O.C. Zienkiewicz, R.L. Taylor. The finite element method. Butterworth Heinemann, 2000.\\
https://www.simplassoftware.com/benchmarks.html\#biblio-58\\
https://github.com/spolanski/CoFEA/tree/master/benchmarks/02-cooks-membrane\\
\textbf{Sources for case ii:} \cite{dealII95}\\
https://www.dealii.org/current/doxygen/deal.II/code\_gallery\_Quasi\_static\_Finite\_strain\_Compressible\_Elasticity.html\\
\textbf{Sources for case iii:} \citep{Simo1992}

\hl{Give mesh details}\\
mesh.1 - 3x3 - 9 CVs\\
mesh.2 - 6x6 - 36 CVs\\
mesh.3 - 12x12 - 144 CVs\\
mesh.4 - 24x24 - 576 CVs\\
mesh.5 - 48-48 - 2304 CVs\\
mesh.6 - 96x96 - 9216 CVs\\
mesh.7 - 192x192 - 36864 CVs

\hl{dd figures: finest mesh stress distributions and deformation Add figures: corner displacement prediction vs average cell width}


\begin{figure}[h!]
   \centering
	\subfigure[Equivalent stress distribution for the mesh with $368\,642$ cells (case ii)]
	{
		\includegraphics[height=0.42\textwidth]{figures/cooksMembrane-sigmaEq.pdf}  
	}
	\subfigure[Convergence of tip (48,60) vertical displacement, normalized using the displacement value from the finest mesh (given in parentheses)]
	{
		\includegraphics[height=0.32\textwidth]{figures/cooksMembrane-tipDispConvergence.pdf} 
	}
   \caption{Convergence of tip displacement and equivalent stress for hyperelastic case.}
   \label{fig:narrowTmember_sigmaEq}
\end{figure}
@Philip, scale for cooksMembrane-sigmaEq.pdf should be from 0 to 0.2 MPa. 


\newpage


\paragraph{Case 6: Vibration of a 3-D Cantilevered Beam}
This 3-D, dynamic, finite strain case geometry consists of a $2 \times 0.2 \times 0.2$ cuboid column (Figure \ref{fig:dynamic_cantilever}), taken from \citet{Tukovic2007}.
A sudden, constant traction $\bb{T} = \left(\sfrac{|\bb{T}|}{\sqrt{2}}\right) \left(1, 1, 0 \right)$ Pa is applied to the upper surface, where the magnitude $|\bb{T}|$ is defined in terms of a dimensionless load factor $\mathcal{F}$ as
\begin{eqnarray}
	|\bb{T}| = \frac{\mathcal{F} E I}{A L^2} \text{ Pa}
\end{eqnarray}
In the current study, $\mathcal{F} = 1$.
A St.\ Venant-Kirchoff material is assumed with $E = 15.293$ MPa, $\nu = 0.3$ and density $\rho = 1000$ kg m$^{-3}$, while the area $A = (0.2)(0.2) = 0.04$ m$^2$ and the second moment of area $I = 0.0001333$ m$^4$.
The geometric and material parameters were chosen for the first natural frequency to be 1 Hz.
\hl{Comment on the meshes}
A fixed time step size of \hl{XXX} s is chosen, corresponding to a \hl{YY} on the coarsest mesh \hl{update as required}.
The total time period is 10 s, corresponding to 10 expceted oscillation periods.
%\begin{figure}[htbp]
%   \centering
%%   \includegraphics[width=0.2\textwidth]{figures/dynamic_cantilever.pdf} 
%   \includegraphics[width=0.2\textwidth]{figures/placeholder.pdf} 
%   \caption{Vibration of a 3-D Cantilevered Beam case geometry, mesh and loading conditions}
%   \label{fig:dynamic_cantilever}
%\end{figure}
\begin{figure}[H]
	\centering
	\subfigure[Case geometry and dimensions]
	{
		\label{fig:dynamic_cantilever_geometry}
   		\includegraphics[scale=1]{figures/cantileverBeam-geometry} 
   	}
   	\qquad
	\subfigure[Hexahedral mesh with 144 cells]
	{
		\label{fig:dynamic_cantilever_mesh}
   		\includegraphics[scale=0.25]{figures/placeholder}  
   	}
	\caption{Vibration of a 3-D Cantilevered Beam case geometry, mesh and loading conditions}
   \label{fig:dynamic_cantilever}
\end{figure}

\paragraph{Case 7: Vibration of an Axial Turbine Blade}
This 3-D, dynamic, finite strain case geometry consists of a twisted axial turbine blade, 0.8 m in height, with a cord length of 0.2 m (Figure \ref{fig:turbine_blade}), and is taken from \citet{Tukovic2007}.
\hl{Zeljko probably has this geometry or a reference for where it came from}
The blade is constrained at one end and subjected to a sudden, constant traction of $\bb{T} = ($\hl{ZZZ,ZZZ,ZZZ} $)$ Pa at the other end.
A St.\ Venant-Kirchoff material is assumed with $E = 15.293$ MPa and $\nu = 0.3$, while the area $A = (0.2)(0.2) = 0.04$ m$^2$ and the second moment of area $I = 0.0001333$ m$^4$.
\hl{Comment on the meshes}
A fixed time step size of \hl{XXX} s is chosen, corresponding to a \hl{YY} on the coarsest mesh \hl{update as required}.
The total time period is \hl{XXX} s, corresponding to \hl{XX} expceted oscillation periods.
\hl{An advantage of this case over the cantilever is that it is complex geometry; a disadvantage is that we do not have a reference solution}
\hl{A mitigation for this disadvantage is we could run it in Abaqus to provide a credible reference}
\begin{figure}[htbp]
   \centering
%   \includegraphics[width=0.2\textwidth]{figures/turbine_blade.pdf} 
   \includegraphics[width=0.2\textwidth]{figures/placeholder.pdf} 
   \caption{Vibration of an axial turbine blade case geometry, mesh and loading conditions}
   \label{fig:turbine_blade}
\end{figure}


%%--------------------------------------------------------------------------------------------------------------------%%
\subsection{Order of Accuracy Verification}
%%--------------------------------------------------------------------------------------------------------------------%%
This section assesses the order of accuracy of the discretisation using a manufactured solution on a cube domain (case 1).
A secondary purpose is to demonstrate that the choice of solution algorithm (Jacobian-free Newton-Krylov vs segregated) does not affect the predictions, assuming iteration errors are small.

The predicted $\sigma_{xx}$ stress distribution for hexahedral mesh with $512\,000$ cells is shown in Figure \ref{fig:mms_stress}(a).
The corresponding cell-wise $\sigma_{xx}$ error distribution is shown in Figure \ref{fig:mms_stress}(b), where the errors of greatest magnitude ($-29$ kPa) occur at the ends of the boundary.
\begin{figure}[htbp]
	\centering
	\subfigure[Predicted $\sigma_{xx}$ stress distribution]
	{
		\label{fig:mms_sxx}
   		\includegraphics[height=0.35\textwidth]{figures/mms_sxx} 
   	}
	\subfigure[Cell-wise $\sigma_{xx}$ error distribution]
	{
		\label{fig:mms_sxx_diff}
   		\includegraphics[height=0.35\textwidth]{figures/mms_sxx_diff}  
   	}
	\caption{Manufactured solution cube case: the predicted $\sigma_{xx}$ stress distribution on a cut-plane for the hexahedral mesh with $512\,000$ cells (left).}
	\label{fig:mms_stress}
\end{figure}

Figure \ref{fig:mms_accuracy}(a) shows the displacement magnitude discretisation errors ($L_2$ and $L_\infty$) as a function of the average cell width for both the hexahedral and polyhedral meshes.
Figure \ref{fig:mms_accuracy}(b) shows the corresponding order of accuracy plots.
The maximum ($L_\infty$) and average ($L_2$) discretisation errors are seen to reduce at an approximately second-order rate for both hexahedral and polyhedral meshes, where the errors are smaller on the hexahedral meshes \hl{check}.
The discretisation errors in the $\sigma_{xx}$ component of stress are shown in Figure \ref{fig:mms_accuracy}(b), and the order of accuracy in \ref{fig:mms_accuracy}(d).
The order of accuracy for the average stress magnitude error is seen to be \hl{XX} for the hexahedral meshes and just over 1.5 for the polyhedral meshes.
In contrast, the maximum stress error order of accuracy is seen to be 1 for both mesh types \hl{check}.
\begin{figure}[htbp]
	\centering
	\subfigure[Displacement magnitude discretisation errors]
	{
   		\includegraphics[width=0.45\textwidth]{figures/mms_dispErrors} 
   	}
	\subfigure[Displacement discretisation error order of accuracy]
	{
   		\includegraphics[width=0.45\textwidth]{figures/mms_disp_orderOfAccuracy}  
   	}
	\subfigure[Stress magnitude discretisation errors]
	{
   		\includegraphics[width=0.45\textwidth]{figures/mms_stressErrors} 
   	}
	\subfigure[Stress discretisation error order of accuracy]
	{
   		\includegraphics[width=0.45\textwidth]{figures/mms_stress_orderOfAccuracy}  
   	}
	\caption{Manufactured solution cube case: the accuracy and order of accuracy for displacement and stress}
	\label{fig:mms_accuracy}
\end{figure}

The presented results have been generated using the Jacobian-free Newton-Raphson solution algorithm; however, minimal differences were seen when using the segregated solution algorithm, and hence, the results are not shown \hl{check}.
Analysis of time and memory requirements is left to subsequent sections.



%%%--------------------------------------------------------------------------------------------------------------------%%
%\subsection{Order of Accuracy Verification - Spherical Cavity}
%%%--------------------------------------------------------------------------------------------------------------------%%
%This section assesses the order of accuracy of the discretisation using the spherical cavity case (case 1).
%A secondary purpose is to demonstrate that the choice of solution algorithm (Jacobian-free Newton-Krylov vs segregated) does not affect the predictions, assuming iteration errors are small.
%
%The predicted axial ($\sigma_{zz}$) stress distribution is shown in Figure \ref{fig:spherical_cavity_stress}, where the peak stress ($2.xxx$ MPa) is just over twice the applied stress ($1$ MPa).
%This is in contrast to the classic 2-D circular hole in an infinite plate case, which exhibits a stress concentration factor of 3.
%A further difference with the 2-D circular hole case is that the local stresses more quickly return to the distant stress state as $R$ increases, with the local stresses being proportional to $\frac{1}{R^3}$ in the 3-D case and  $\frac{1}{R^2}$ in the 2-D case.
%\begin{figure}[htbp]
%   \centering
%%   \includegraphics[width=0.2\textwidth]{figures/spherical_cavity_stress.pdf} 
%   \includegraphics[width=0.2\textwidth]{figures/placeholder.pdf} 
%   \caption{Spherical cavity case: $\sigma_{zz}$ stress distribution \hl{use Reflect in ParaView to make a nice image}}
%   \label{fig:spherical_cavity_stress}
%\end{figure}
%
%Figure \ref{fig:spherical_cavity_accuracy} shows the discretisation errors ($L_2$ and $L_\infty$) in $\sigma_{zz}$ as a function of the average cell width.
%The errors can be seen to \hl{describe on the average/max error trends in graphs}.
%\hl{Comment on the order of accuracy: does it show what was expected or not?}
%\hl{Conclude 1: order of accuracy of the discretisation is XXX}
%\hl{Conclude 2: solution algorithm does not affect the answer}
%\hl{There is no need to show segregated results if they are the same: just state that they are the same}
%\hl{There is no need to show time and memory requirements: leave to the next section}
%\begin{figure}[htbp]
%   \centering
%%   \includegraphics[width=0.2\textwidth]{figures/spherical_cavity_error.pdf} 
%   \includegraphics[width=0.2\textwidth]{figures/placeholder.pdf} 
%   \caption{Spherical cavity case: discretisation error as a function of average cell width \hl{disp and stress errors if we have them}}
%   \label{fig:spherical_cavity_accuracy}
%\end{figure}



%%--------------------------------------------------------------------------------------------------------------------%%
\subsection{Time and Memory Requirements}
%%--------------------------------------------------------------------------------------------------------------------%%
This section presents the time and memory requirements of the proposed Jacobian-free Newton Krylov approach for all six cases described in Section \ref{sec:case_descriptions}, where several mesh densities are examined.
Time and memory requires from the classic segregated approach are given for comparison, along with the requirements from commercial finite element software Abaqus (version XXX): \hl{ask Dylan to create the Abaqus results when we are happy the paper will not change}.
The finite element approach uses a coupled solution algorithm and direct linear solver, where a Newton-Raphson method is used for resolving nonlinearities.
\hl{Take care when comparing times between different hardware}

Figure \ref{fig:time_memory_images} provides a collage of the equivalent (von Mises) stress fields for the \hl{six} cases.
\begin{figure}[htbp]
   \centering
%   \includegraphics[width=0.2\textwidth]{figures/time_memory_images.pdf} 
   \includegraphics[width=0.2\textwidth]{figures/placeholder.pdf} 
   \caption{Collage of the equivalent (von Mises) stress fields for the \hl{six} cases}
   \label{fig:time_memory_images}
\end{figure}

Table \ref{tab:times_memory} lists the wall clock times (time according to a clock on the wall) and maximum memory usage according to the GNU time utility.
All clock times and memory usage were generated using \hl{hardware details} using one CPU core.
Times and maximum memory usage were recorded using the GNU time utility.
\hl{Give details of relevant numerical settings, e.g. linear solver, preconditioner, Rhie-Chow scaling, globalisation strategy if any}.
Multi-CPU-core parallelisation is examiend in Section \ref{sec:parallelisation}.
\begin{table}[htb]
	\centering
		\begin{tabular}{llll}
			\hline
			Case & Number of Cells & Time (in s) & Memory (in MB) \\
			\hline 
			Spherical cavity & 1,234 & 345 & 1,234  \\
			Spherical cavity & 12,345 & 345 & 1,234  \\
			Spherical cavity & 123,456 & 345 & 1,234  \\
			Case 2, etc & 123,456 & 345 & 1,234  \\
			Case 3, etc & 123,456 & 345 & 1,234  \\
			Case 4, etc & 123,456 & 345 & 1,234  \\
			\hline
		\end{tabular}
	\caption{Execution times and maximum memory usage \hl{speed-up column?}}
	\label{tab:times_memory}
\end{table}

The trends shown in Table \ref{tab:times_memory} are common to all typical modern computer systems, however, the exact values depend on the particular details of the CPU, the memory configuration and the operating system.
To highlight the effect of hardware specification, Table \ref{tab:times_memory_spec2} lists the time and memory usage for a different system: \hl{e.g. Mac M2/M3 seem to give excellent performance vs Meluxina AMD EPYC cores}.
\hl{Describe the difference, e.g. 2-3 faster but same memory usage}
\hl{Additional comments/insights, e.g. time trends are the same for both systems}
\hl{We could even include multiple systems here, e.g. Mac Studio vs Meluxina AMD vs Zagreb Intel workstation vs Intel i9/i7}
\begin{table}[htb]
	\centering
		\begin{tabular}{lllll}
			\hline
			Hardware & Case & Number of Cells & Time (in s) & Memory (in MB) \\
			\hline 
			Mac Studio, M2 Ultra & Spherical cavity & 1,234 & 345 & 1,234  \\
			Mac Studio, M2 Ultra & Spherical cavity & 12,345 & 345 & 1,234  \\
			Mac Studio, M2 Ultra & Spherical cavity & 123,456 & 345 & 1,234  \\
			Meluxina, AMD EPYC & Spherical cavity & 1,234 & 345 & 1,234  \\
			Meluxina, AMD EPYC & Spherical cavity & 12,345 & 345 & 1,234  \\
			Meluxina, AMD EPYC & Spherical cavity & 123,456 & 345 & 1,234  \\
			\hline
		\end{tabular}
	\caption{Execution times and maximum memory usage for \hl{Hardware Spec 2}}
	\label{tab:times_memory_spec2}
\end{table}


%%--------------------------------------------------------------------------------------------------------------------%%
\subsection{Effect of Mesh Type}
%%--------------------------------------------------------------------------------------------------------------------%%
To highlight the effect of mesh type on the performance of the proposed Jacobian-free Newton-Krylov approach, case \hl{X} is re-examined using several mesh types:
(i) structured hexahedral; (ii) structured tetrahedral; (iii) unstructured tetehrahedral; and (iv) unstructured poyhedral.
%Pick one case and show its timings and memory for tet (Gmsh), hex and poly (Gmsh + polyDualMesh).
The hexahedral and tetahedral meshes have been generated using the Gmsh utility \citep{geuzaine2009gmsh} and the polyhedral mesh has been created by converting a tetrahedral mesh using the OpenFOAM \texttt{polyDualMesh} utility.

Table \ref{tab:mesh_types} lists the execution times and total number of linear solver iterations for the different mesh types and densities.
\hl{Comment on the results: e.g. fastest, slowest, most/least iterations, etc}
\hl{Provide insights, if any: e.g. why is one faster or slower}
\hl{Conclusion: mesh type does or does not affect the performance.}
\begin{table}[htb]
	\centering
		\begin{tabular}{llll}
			\hline
			Mesh Type & Number of Cells & Time (in s) & Linear Solver Iterations  \\
			\hline 
			Structured hexahedral & 1,234 & 345 & 1,234  \\
			Structured hexahedral & 12,345 & 345 & 1,234  \\
			Structured hexahedral & 123,456 & 345 & 1,234  \\
			Structured tetrahedral & 1,234 & 345 & 1,234  \\
			Structured tetrahedral & 12,345 & 345 & 1,234  \\
			Structured tetrahedral & 123,456 & 345 & 1,234  \\
			Unstructured tetrahedral & 1,234 & 345 & 1,234  \\
			Unstructured tetrahedral & 12,345 & 345 & 1,234  \\
			Unstructured tetrahedral & 123,456 & 345 & 1,234  \\
			Unstructured polyhedral & 1,234 & 345 & 1,234  \\
			Unstructured polyhedral & 12,345 & 345 & 1,234  \\
			Unstructured polyhedral & 123,456 & 345 & 1,234  \\
			\hline
		\end{tabular}
	\caption{Execution times on Case \hl{X} for different mesh types}
	\label{tab:mesh_types}
\end{table}


%%--------------------------------------------------------------------------------------------------------------------%%
\subsection{Effect of the Preconditioner Choice}
%%--------------------------------------------------------------------------------------------------------------------%%
A critical factor contributing to the performance of Jacobian-free Newton Krylov methods is the formulation of the linear solver preconditioner and related linear solver settings.
In this section, three choices of preconditioner are compared:
\begin{itemize}
	\item \textbf{LU} - A LU decomposition direct solver \hl{Is this MUMPS? To be checked}. A direct solver is expected to be the more robust but suffer from excessive time and memory requirements for larger numbers of unknowns.
	\item \textbf{ILU(N)} - Incomplete LU decomposition with $N$ fill-in. ILU(N) is expected to have lower memory requirements but at the expense of robustness. Additionally, as the system of unknowns becomes larger, the number of ILU(N) iterations is expected to increase. As the fill-in factor $N$ is increased, the performance of ILU(N) approaches that of the LU direct solver.
	\item \textbf{Algebraic multigrid} - The HYPRE Boomerang parallelised multigrid preconditioner. Multigrid approaches have the potential to offer superior performance than other methods for larger problems, with near linear scaling of time and memory requirement.
\end{itemize}

An additional consideration when selecting a preconditioner is its ability to scale in parallel as the number of CPU cores increases.
From this perspective, the iterative approaches (ILU(N) and multigrid) are expected to show better parallel scaling than direct methods (LU).
Analysis of this point is left to Section \ref{sec:parallelisation}.

Table \ref{tab:preconditioner} presents the execution times and memory requirements for cases \hl{X, Y and Z} for different mesh densities.
\hl{Comment on the results: e.g. fastest, slowest, most/least iterations, etc}
\hl{Provide insights, if any: e.g. why is one faster or slower}
\hl{Conclusion: which preconditioner if 'best' for which situation: probably LU is best for 'small' cases and multigrid for 'large' cases}
\begin{table}[htb]
	\centering
		\begin{tabular}{lllll}
			\hline
			Case & Number of Cells & Preconditioner & Time (in s) & Memory (in MB)  \\
			\hline 
			Case X & 1,234 & LU & 345 & 1,234  \\
			Case X & 12,345 & LU & 345 & 1,234  \\
			Case X & 123,456 & LU & 345 & 1,234  \\
			Case X & 1,234 & ILU(0) & 345 & 1,234  \\
			Case X & 12,345 & ILU(0) & 345 & 1,234  \\
			Case X & 123,456 & ILU(0) & 345 & 1,234  \\
			Case X & 1,234 & Multigrid & 345 & 1,234  \\
			Case X & 12,345 & Multigrid & 345 & 1,234  \\
			Case X & 123,456 & Multigrid & 345 & 1,234  \\
			Case Y & 1,234 & LU & 345 & 1,234  \\
			Case Z & 1,234 & LU & 345 & 1,234  \\
			\hline
		\end{tabular}
	\caption{Execution times and maximum memory usage for different preconditioners on varying cases and mesh densities \hl{Try other value of N for ILU?}}
	\label{tab:preconditioner}
\end{table}


\hl{Other linear solver settings: mention these but no need for analyses}

In GMRES, we must choose the value of the "restarts" parameter; the default in PETSc of 30 does not always seem good enough (I have been setting it to 100). We could show its affect on one case. I think the optimal choice is linked with the choice of preconditioner (a better preconditioner means we can use a small restart value) so maybe we include this with the "preconditioner choices" section.
\hl{I suggest we do not add an analysis of this: instead we can just mention it}

This can also be considered a linear solver setting. For segregated, we always use a relative tolerance of 0.1, but initial tests for JFNK show that 0.1 is too loose and 1e-3 seems better, although maybe there is no difference with using 1e-6.
\hl{I suggest we do not add an analysis of this: instead we can just mention it}



%%--------------------------------------------------------------------------------------------------------------------%%
\subsection{Effect of Rhie-Chow Stabilisation}
%%--------------------------------------------------------------------------------------------------------------------%%
This section highlights a key effect in the performance of the proposed Jacobian-free Newton Krylov method: the choice of the global scaling factor $\alpha$ in the Rhie-Chow stabilisation (Equation \ref{eq:RhieChow}).
Without this (or a similar) stabilisation term, zero-energy oscillations, such as checkerboarding, may appear in the solution fields.
As the amount of stabilisation is increased (increasing $\alpha$), these numerical modes are quelled and the solution is stabilisation; however, at some point, further increases in amount of stabilisation reduce the accuracy of the discretisation due to oversmoothing.
Consequently, a good choice of the stabilisation global scaling factor $\alpha$ is one which is sufficiently high to quell oscillations but not higher.
This challenge is related to the discretisation and hence is common to all solution algorithms, including segregated and Jacobian-free Newton Krylov methods.
Nonetheless, the amount of stabilisation can affect the convergence of the linear solver in Jacobian-free Newton Krylov methods, for example, as examined by \citet{Nishikawa} for a \hl{XXX} Euler flow finite volume formulation.

Table \ref{tab:rhie_chow} presents the execution times and total number of linear solver iterations for the case \hl{XX} for $\alpha = \left[ 0.01, 0.1, 1 \right]$ for several mesh densities.
\hl{Comment on the results: e.g. fastest, slowest, most/least iterations, if any cases diverged or needed a higher 'restarts' value, etc}
\hl{Provide insights, if any: e.g. why is one faster or slower}
\begin{table}[htb]
	\centering
		\begin{tabular}{lllll}
			\hline
			Case & Number of Cells & $\alpha$ & Time (in s) & Linear Solver Iterations  \\
			\hline 
			Idealised Ventricle & 1,234 & 0.01 & 345 & 1,234  \\
			Idealised Ventricle & 12,345 & 0.1 & 345 & 1,234  \\
			Idealised Ventricle & 123,456 & 1.0 & 345 & 1,234  \\
			Axial Turbine & 1,234 & 0.01 & diverged & diverged  \\
			Axial Turbine & 12,345 & 0.1 & 345 & 1,234  \\
			Axial Turbine & 123,456 & 1.0 & 345 & 1,234  \\
			\hline
		\end{tabular}
	\caption{Execution times and total number linear solver iterations for different values of the Rhie-Chow stabilisation factor $\alpha$}
	\label{tab:rhie_chow}
\end{table}

Figure \ref{fig:rhie_chow} shows a comparison of the stress \hl{(or displacement)} along the line \hl{XXX -> we need to show the effect on accuracy for different values of alpha}
\begin{figure}[htbp]
   \centering
%   \includegraphics[width=0.2\textwidth]{figures/rhie_chow.pdf} 
   \includegraphics[width=0.2\textwidth]{figures/placeholder.pdf} 
   \caption{Stress predictions along the line \hl{XXX} for the \hl{YYY} case using different values of the Rhie-Chow stabilisation factor $\alpha$}
   \label{fig:rhie_chow}
\end{figure}


%%--------------------------------------------------------------------------------------------------------------------%%
\subsection{Effect of Globalisation Strategies}
%%--------------------------------------------------------------------------------------------------------------------%%
\hl{We already have many section so it may be better to just mention this rather than providing an analysis}
%As a by the way, I think the default line search in PETSc may not be the best one for JFNK.



%%--------------------------------------------------------------------------------------------------------------------%%
\subsection{Parallelisation}
\label{sec:parallelisation}
%%--------------------------------------------------------------------------------------------------------------------%%
In this final analysis, the multi-CPU-core parallel scaling performance of the proposed Jacobian-free Newton Krylov method is examined.
Two types of parallel scaling analyses are performed \cite{Knoll2004}:
\begin{itemize}
	\item Strong scaling study: Strong scaling measures how the execution time of a fixed problem size (fixed number of cells) decreases as the number of CPU cores increases.
	Good strong scaling indicates that an application effectively utilises additional CPU cores without significant overhead.
	In contrast, poor strong scaling suggests that adding more cores does not significantly reduce the execution time, often due to increased communication or synchronisation overhead.

	\item Weak scaling study: Weak scaling measures how the execution time changes as the problem size (the number of cells) and the number of CPU cores increase proportionally, where the problem size per CPU core remains (approximately) constant.
	Good weak scaling indicates that the application can efficiently manage larger workloads with more cores without a significant increase in execution time.
	Poor weak scaling implies that the application struggles to maintain performance as the problem size and core count increase.
\end{itemize}

The results from the strong scaling study are shown in Figure \ref{fig:parallelisation_strong}.
The speedup $S$ is defined as $S = \sfrac{t_1}{t_p}$, where $t_1$ is the clock time on one CPU core and $t_p$ is the clock time on $P$ CPU cores.
In the ideal case, the speedup should double when the number of cores is doubled.
In reality, inter-CPU-core communication reduces the parallel scaling efficiency below the ideal.
\hl{Comment on the results: e.g. fastest, slowest, most/least iterations, best/worst scaling}
\hl{Provide insights, if any: e.g. why is one faster or slower}
\begin{figure}[htbp]
	\centering
	\subfigure[Clock times vs number of CPU cores]
	{
		\label{fig:parallel_strong_times}
%		\includegraphics[width=0.2\textwidth]{./figures/parallel_strong_times.pdf}
   		\includegraphics[width=0.2\textwidth]{figures/placeholder.pdf} 
   	}
	\subfigure[Speedup $S$ vs number of CPU cores]
	{
		\label{fig:parallel_strong_speedup}
%		\includegraphics[width=0.2\textwidth]{./figures/parallel_strong_speedup.pdf}
   		\includegraphics[width=0.2\textwidth]{figures/placeholder.pdf} 
   	}
	\caption{Strong parallel scaling study comparing the performance of three preconditioning strategies: a LU direct solver, and ILU(N) and multigrid iterative solvers}
	\label{fig:parallelisation_strong}
\end{figure}

The weak scaling results are shown in Figure \ref{fig:parallelisation_weak}.
The weak scaling efficiency $\eta_w$ is defined as $\eta_w = \sfrac{t^[w]_1}{t^[w]_p}$, where $t^[w]_1$ is the clock time on one CPU core and $t^[w]_p$ is the clock time on $P$ CPU cores where the problem size per CPU core is constant.
In the ideal case, the efficiency should be unity, but inter-CPU-core communication reduces it.
\hl{Comment on the results: e.g. fastest, slowest, most/least iterations, best/worst scaling}
\hl{Provide insights, if any: e.g. why is one faster or slower}
\begin{figure}[htbp]
	\centering
	\subfigure[Clock times vs number of CPU cores]
	{
		\label{fig:parallel_weak_times}
%		\includegraphics[width=0.2\textwidth]{./figures/parallel_weak_times.pdf}
   		\includegraphics[width=0.2\textwidth]{figures/placeholder.pdf} 
   	}
	\subfigure[Weak scaling efficiency $\eta_w$ vs number of CPU cores]
	{
		\label{fig:parallel_weak_speedup}
%		\includegraphics[width=0.2\textwidth]{./figures/parallel_weak_efficiency.pdf}
   		\includegraphics[width=0.2\textwidth]{figures/placeholder.pdf} 
   	}
	\caption{Weak parallel scaling study comparing the performance of three preconditioning strategies: a LU direct solver, and ILU(N) and multigrid iterative solvers}
	\label{fig:parallelisation_weak}
\end{figure}

%Comments from \cite{Knoll2004}:
%"The first is a scalable implementation, in the sense that time per iteration is reduced in inverse proportion to the number of processors (strong scaling), or that time per iteration is constant as problem size and processor number are scaled proportionally (weak scaling). The second is good per processor performance on contemporary cache-based microprocessors. The third is algorithmic scalability, in the sense that the number of iterations to convergence does not grow with increased numbers of processors (or problem size). The third factor arises because the requirement of a scalable implementation generally forces parameterized changes in the algorithm as the number of processors grows. If the convergence is allowed to degrade, however, the overall execution is not scalable, and this must be countered algorithmically."


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusions} \label{sec:conclusion}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
In the current work, a Jacobian-free Newton-Krylov solution algorithm has been proposed for solid mechanics problems discretised using the cell-centred finite volume method.
A compact-stencil discretisation of the diffusion term is proposed as the preconditioner matrix, allowing a straightforward extension of existing segregated solution frameworks.
The key findings of the work are:
\begin{itemize}
	\item Main results
	\item Main important choices
	\item How it compares to segregated methods and FE (Abaqus)
\end{itemize}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\backmatter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bmhead{Acknowledgments}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
This project has received funding from the European Research Council (ERC) under the European Union’s Horizon 2020 research and innovation programme (Grant Agreement No. 101088740).
Financial support is gratefully acknowledged from the Irish Research Council through the Laureate programme, grant number IRCLA/2017/45, from Bekaert through the University Technology Centre (UTC phases I and II) at UCD (www.ucd.ie/bekaert), from I-Form, funded by Science Foundation Ireland (SFI) Grant Numbers 16/RC/3872 and {RC2302\_2}, co-funded under European Regional Development Fund and by I-Form industry partners, and from NexSys, funded by SFI Grant Number 21/SPP/3756.
Additionally, the authors wish to acknowledge the DJEI/DES/SFI/HEA Irish Centre for High-End Computing (ICHEC) for the provision of computational facilities and support (www.ichec.ie), and part of this work has been carried out using the UCD ResearchIT Sonic cluster which was funded by UCD IT Services and the UCD Research Office.
\hl{Ivan/Zeljko: add any additional acknowledgements here}



\newpage

\begin{appendices}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Body Force for the Method of Manufactured Solutions Case} \label{app:mms}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The body force for the manufactured solution case is
\begin{align}
\bb{f}_b = 
    \begin{pmatrix}
    \lambda
    \left[
        8 a_y \pi^2 \cos(4\pi x) \cos(2\pi y) \sin(\pi z) \right. \\
        \quad + 4 a_z \pi^2 \cos(4\pi x) \cos(\pi z) \sin(2\pi y) \\
        \quad \left. - 16 a_x \pi^2 \sin(4\pi x) \sin(2\pi y) \sin(\pi z)
    \right] \\
    + \mu
    \left[
        8 a_y \pi^2 \cos(4\pi x) \cos(2\pi y) \sin(\pi z) \right. \\
        \quad + 4 a_z \pi^2 \cos(4\pi x) \cos(\pi z) \sin(2\pi y) \\
        \quad \left. - 5 a_x \pi^2 \sin(4\pi x) \sin(2\pi y) \sin(\pi z)
    \right] \\
    - 32 a_x \mu_ \pi^2 \sin(4\pi x) \sin(2\pi y) \sin(\pi z) \\
    \\
    \lambda
    \left[
        8 a_x \pi^2 \cos(4\pi x) \cos(2\pi y) \sin(\pi z) \right. \\
        \quad + 2 a_z \pi^2 \cos(2\pi y) \cos(\pi z) \sin(4\pi x) \\
        \quad \left. - 4 a_y \pi^2 \sin(4\pi x) \sin(2\pi y) \sin(\pi z)
    \right] \\
    + \mu
    \left[
        8 a_x \pi^2 \cos(4\pi x) \cos(2\pi y) \sin(\pi z) \right. \\
        \quad + 2 a_z \pi^2 \cos(2\pi y) \cos(\pi z) \sin(4\pi x) \\
        \quad \left. - 17 a_y \pi^2 \sin(4\pi x) \sin(2\pi y) \sin(\pi z)
    \right] \\
    - 8 a_y \mu_ \pi^2 \sin(4\pi x) \sin(2\pi y) \sin(\pi z) \\
    \\
    \lambda
    \left[
        4 a_x \pi^2 \cos(4\pi x) \cos(\pi z) \sin(2\pi y) \right. \\
        \quad + 2 a_y \pi^2 \cos(2\pi y) \cos(\pi z) \sin(4\pi x) \\
        \quad \left. - a_z \pi^2 \sin(4\pi x) \sin(2\pi y) \sin(\pi z)
    \right] \\
    + \mu
    \left[
        4 a_x \pi^2 \cos(4\pi x) \cos(\pi z) \sin(2\pi y) \right. \\
        \quad + 2 a_y \pi^2 \cos(2\pi y) \cos(\pi z) \sin(4\pi x) \\
        \quad \left. - 20 a_z \pi^2 \sin(4\pi x) \sin(2\pi y) \sin(\pi z)
    \right] \\
    - 2 a_z \mu_ \pi^2 \sin(4\pi x) \sin(2\pi y) \sin(\pi z)
    \end{pmatrix}
\end{align}
%\begin{eqnarray}
%\bb{f}_b =
%	\begin{pmatrix}
%	\lambda
%	\left[
%	    8 a_y \pi^2 \cos(4\pi x) \cos(2\pi y) \sin(\pi z)
%	  + 4 a_z \pi^2 \cos(4\pi x) \cos(\pi z) \sin(2\pi y)
%	  - 16 a_x \pi^2 \sin(4\pi x) \sin(2\pi y) \sin(\pi z)
%	\right]
%	+ \mu
%	\left[
%	    8 a_y \pi^2 \cos(4\pi x) \cos(2\pi y) \sin(\pi z)
%	  + 4 a_z \pi^2 \cos(4\pi x) \cos(\pi z) \sin(2\pi y)
%	  - 5 a_x \pi^2 \sin(4\pi x) \sin(2\pi y) \sin(\pi z)
%	\right]
%	- 32 a_x \mu_ \pi^2 \sin(4\pi x) \sin(2\pi y) \sin(\pi z) \\
%	\lambda
%	\left[
%	    8 a_x \pi^2 \cos(4\pi x) \cos(2\pi y) \sin(\pi z)
%	  + 2 a_z \pi^2 \cos(2\pi y) \cos(\pi z) \sin(4\pi x)
%	  - 4 a_y \pi^2 \sin(4\pi x) \sin(2\pi y) \sin(\pi z)
%	\right]
%	+ \mu
%	\left[
%	    8 a_x \pi^2 \cos(4\pi x) \cos(2\pi y) \sin(\pi z)
%	  + 2 a_z \pi^2 \cos(2\pi y) \cos(\pi z) \sin(4\pi x)
%	  - 17 a_y \pi^2 \sin(4\pi x) \sin(2\pi y) \sin(\pi z)
%	\right]
%	- 8 a_y \mu_ \pi^2 \sin(4\pi x) \sin(2\pi y) \sin(\pi z) \\
%	\lambda
%	\left[
%	    4 a_x \pi^2 \cos(4\pi x) \cos(\pi z) \sin(2\pi y)
%	  + 2 a_y \pi^2 \cos(2\pi y) \cos(\pi z) \sin(4\pi x)
%	  - a_z \pi^2 \sin(4\pi x) \sin(2\pi y) \sin(\pi z)
%	\right]
%	+ \mu
%	\left[
%	    4 a_x \pi^2 \cos(4\pi x) \cos(\pi z) \sin(2\pi y)
%	  + 2 a_y \pi^2 \cos(2\pi y) \cos(\pi z) \sin(4\pi x)
%	  - 20 a_z \pi^2 \sin(4\pi x) \sin(2\pi y) \sin(\pi z)
%	\right]
%	- 2 a_z \mu_ \pi^2 \sin(4\pi x) \sin(2\pi y) \sin(\pi z)
%	\end{pmatrix}
%\end{eqnarray}
where $\mu$ and $\lambda$ are the first and second Lam\'{e} parameters, respectively.

\end{appendices}


\bibliography{bibliography}% common bib file


\end{document}
